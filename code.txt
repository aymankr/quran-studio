=== Reverb/CustomReverbView.swift ===
import SwiftUI

struct CustomReverbView: View {
    @ObservedObject var audioManager: AudioManager
    @Environment(\.presentationMode) var presentationMode
    @State private var showingResetAlert = false
    
    // États locaux pour les paramètres personnalisés
    @State private var wetDryMix: Float = 35
    @State private var size: Float = 0.82
    @State private var decayTime: Float = 2.0
    @State private var preDelay: Float = 75.0
    @State private var crossFeed: Float = 0.5
    @State private var highFrequencyDamping: Float = 50.0
    @State private var density: Float = 70.0
    @State private var hasCrossFeed: Bool = false
    
    // Couleurs du thème
    private let backgroundColor = Color(red: 0.08, green: 0.08, blue: 0.13)
    private let sliderColor = Color.blue
    
    var body: some View {
        ZStack {
            backgroundColor.edgesIgnoringSafeArea(.all)
            
            ScrollView(.vertical, showsIndicators: true) {
                VStack(spacing: 15) {
                    Text("Réverbération Personnalisée")
                        .font(.system(size: 22, weight: .bold, design: .rounded))
                        .foregroundColor(.white)
                        .padding(.top, 15)
                    
                    // Description
                    Text("Ajustez les paramètres pour créer votre propre atmosphère acoustique.")
                        .font(.subheadline)
                        .foregroundColor(.white.opacity(0.8))
                        .multilineTextAlignment(.center)
                        .padding(.horizontal)
                        .padding(.bottom, 5)
                    
                    // Zone de réglages
                    VStack(spacing: 15) {
                        // Mélange Wet/Dry
                        DirectSliderView(
                            title: "Mélange (Wet/Dry)",
                            value: $wetDryMix,
                            range: 0...100,
                            step: 1,
                            icon: "slider.horizontal.3",
                            displayText: { String(Int($0)) + "%" },
                            onChange: { newValue in
                                wetDryMix = newValue
                                updateCustomReverb()
                            }
                        )
                        
                        // Taille de l'espace
                        DirectSliderView(
                            title: "Taille de l'espace",
                            value: $size,
                            range: 0...1,
                            step: 0.01,
                            icon: "rectangle.expand.vertical",
                            displayText: { String(Int($0 * 100)) + "%" },
                            onChange: { newValue in
                                size = newValue
                                updateCustomReverb()
                            }
                        )
                        
                        // Durée de réverbération
                        DirectSliderView(
                            title: "Durée de réverbération",
                            value: $decayTime,
                            range: 0.1...8,
                            step: 0.1,
                            icon: "clock",
                            displayText: { String(format: "%.1fs", $0) },
                            onChange: { newValue in
                                decayTime = newValue
                                updateCustomReverb()
                            },
                            highPriority: true
                        )
                        
                        // Pré-délai
                        DirectSliderView(
                            title: "Pré-délai",
                            value: $preDelay,
                            range: 0...200,
                            step: 1,
                            icon: "arrow.left.and.right",
                            displayText: { String(Int($0)) + "ms" },
                            onChange: { newValue in
                                preDelay = newValue
                                updateCustomReverb()
                            }
                        )
                        
                        // Cross-feed
                        VStack(alignment: .leading) {
                            Text("Diffusion stéréo (Cross-feed)")
                                .font(.headline)
                                .foregroundColor(.white)
                            
                            VStack(spacing: 12) {
                                Toggle("Activer", isOn: $hasCrossFeed)
                                    .toggleStyle(SwitchToggleStyle(tint: sliderColor))
                                    .foregroundColor(.white)
                                    .onChange(of: hasCrossFeed) { _ in
                                        updateCustomReverb()
                                    }
                                
                                if hasCrossFeed {
                                    HStack {
                                        DirectSlider(
                                            value: $crossFeed,
                                            range: 0...1,
                                            step: 0.01,
                                            onChange: { newValue in
                                                crossFeed = newValue
                                                updateCustomReverb()
                                            }
                                        )
                                        .accentColor(sliderColor)
                                        .disabled(!hasCrossFeed)
                                        
                                        Text(String(Int(crossFeed * 100)) + "%")
                                            .foregroundColor(.white)
                                            .frame(width: 50, alignment: .trailing)
                                    }
                                }
                            }
                        }
                        .padding()
                        .background(Color.black.opacity(0.2))
                        .cornerRadius(12)
                        
                        // Atténuation des aigus
                        DirectSliderView(
                            title: "Atténuation des aigus",
                            value: $highFrequencyDamping,
                            range: 0...100,
                            step: 1,
                            icon: "waveform.path.ecg",
                            displayText: { String(Int($0)) + "%" },
                            onChange: { newValue in
                                highFrequencyDamping = newValue
                                updateCustomReverb()
                            }
                        )
                        
                        // Densité
                        DirectSliderView(
                            title: "Densité",
                            value: $density,
                            range: 0...100,
                            step: 1,
                            icon: "wave.3.right",
                            displayText: { String(Int($0)) + "%" },
                            onChange: { newValue in
                                density = newValue
                                updateCustomReverb()
                            }
                        )
                    }
                    .padding(.horizontal)
                    
                    // Boutons
                    HStack(spacing: 15) {
                        Button(action: {
                            showingResetAlert = true
                        }) {
                            Text("Réinitialiser")
                                .font(.headline)
                                .foregroundColor(.white)
                                .padding()
                                .frame(maxWidth: .infinity)
                                .frame(height: 50)
                                .background(Color.gray.opacity(0.6))
                                .cornerRadius(12)
                        }
                        
                        Button(action: {
                            presentationMode.wrappedValue.dismiss()
                        }) {
                            Text("Fermer")
                                .font(.headline)
                                .foregroundColor(.white)
                                .padding()
                                .frame(maxWidth: .infinity)
                                .frame(height: 50)
                                .background(sliderColor)
                                .cornerRadius(12)
                        }
                    }
                    .padding(.vertical, 20)
                    .padding(.horizontal)
                }
            }
        }
        .alert(isPresented: $showingResetAlert) {
            Alert(
                title: Text("Réinitialiser les paramètres"),
                message: Text("Êtes-vous sûr de vouloir revenir aux paramètres par défaut?"),
                primaryButton: .destructive(Text("Réinitialiser")) {
                    resetToDefaults()
                },
                secondaryButton: .cancel(Text("Annuler"))
            )
        }
        .onAppear {
            loadCurrentSettings()
            
            // S'assurer que nous sommes en mode personnalisé
            if audioManager.selectedReverbPreset != .custom {
                audioManager.updateReverbPreset(.custom)
            }
        }
    }
    
    // MARK: - Helper Methods
    
    /// Charge les paramètres actuels
    private func loadCurrentSettings() {
        let defaultSettings = CustomReverbSettings.default
        wetDryMix = defaultSettings.wetDryMix
        size = defaultSettings.size
        decayTime = defaultSettings.decayTime
        preDelay = defaultSettings.preDelay
        crossFeed = defaultSettings.crossFeed
        highFrequencyDamping = defaultSettings.highFrequencyDamping
        density = defaultSettings.density
        hasCrossFeed = false
    }
    
    /// Met à jour les paramètres de réverbération personnalisés
    private func updateCustomReverb() {
        // Créer une structure de paramètres personnalisés
        let customSettings = CustomReverbSettings(
            size: size,
            decayTime: decayTime,
            preDelay: preDelay,
            crossFeed: crossFeed,
            wetDryMix: wetDryMix,
            highFrequencyDamping: highFrequencyDamping,
            density: density
        )
        
        // Mettre à jour les paramètres statiques
        ReverbPreset.updateCustomSettings(customSettings)
        
        // Appliquer immédiatement si en mode custom
        if audioManager.selectedReverbPreset == .custom {
            audioManager.updateReverbPreset(.custom)
            
            // Mettre à jour le cross-feed si disponible
            audioEngineService?.updateCrossFeed(enabled: hasCrossFeed, value: crossFeed)
        }
    }
    
    /// Réinitialise aux valeurs par défaut
    private func resetToDefaults() {
        let defaultSettings = CustomReverbSettings.default
        
        withAnimation(.easeInOut(duration: 0.3)) {
            wetDryMix = defaultSettings.wetDryMix
            size = defaultSettings.size
            decayTime = defaultSettings.decayTime
            preDelay = defaultSettings.preDelay
            crossFeed = defaultSettings.crossFeed
            highFrequencyDamping = defaultSettings.highFrequencyDamping
            density = defaultSettings.density
            hasCrossFeed = false
        }
        
        // Appliquer immédiatement
        updateCustomReverb()
    }
    
    /// Référence à l'AudioEngineService
    private var audioEngineService: AudioEngineService? {
        return audioManager.audioEngineService
    }
}

// MARK: - DirectSlider avec Binding

/// Slider optimisé avec support de Binding
struct DirectSlider: View {
    @Binding var value: Float
    let range: ClosedRange<Float>
    let step: Float
    let onChange: (Float) -> Void
    let highPriority: Bool
    
    @State private var isEditingNow = false
    @State private var lastUpdateTime = Date()
    private let throttleInterval: TimeInterval = 0.05
    private let highPriorityInterval: TimeInterval = 0.02
    
    init(value: Binding<Float>, range: ClosedRange<Float>, step: Float, onChange: @escaping (Float) -> Void, highPriority: Bool = false) {
        self._value = value
        self.range = range
        self.step = step
        self.onChange = onChange
        self.highPriority = highPriority
    }
    
    var body: some View {
        Slider(
            value: $value,
            in: range,
            step: step,
            onEditingChanged: { editing in
                isEditingNow = editing
                
                if !editing {
                    // Appliquer immédiatement à la fin de l'édition
                    onChange(value)
                }
            }
        )
        .onChange(of: value) { newValue in
            // Pendant l'édition, appliquer avec throttling
            if isEditingNow {
                let now = Date()
                let interval = highPriority ? highPriorityInterval : throttleInterval
                
                if now.timeIntervalSince(lastUpdateTime) >= interval {
                    onChange(newValue)
                    lastUpdateTime = now
                }
            } else {
                // Si pas en édition, appliquer immédiatement
                onChange(newValue)
            }
        }
    }
}

// MARK: - DirectSliderView avec Binding

/// Vue complète pour un slider avec titre, icône et affichage de valeur
struct DirectSliderView: View {
    let title: String
    @Binding var value: Float
    let range: ClosedRange<Float>
    let step: Float
    let icon: String
    let displayText: (Float) -> String
    let onChange: (Float) -> Void
    let highPriority: Bool
    
    init(title: String, value: Binding<Float>, range: ClosedRange<Float>, step: Float, icon: String,
         displayText: @escaping (Float) -> String, onChange: @escaping (Float) -> Void, highPriority: Bool = false) {
        self.title = title
        self._value = value
        self.range = range
        self.step = step
        self.icon = icon
        self.displayText = displayText
        self.onChange = onChange
        self.highPriority = highPriority
    }
    
    private let sliderColor = Color.blue
    
    var body: some View {
        VStack(alignment: .leading, spacing: 8) {
            HStack {
                Image(systemName: icon)
                    .foregroundColor(.white.opacity(0.7))
                Text(title)
                    .font(.headline)
                    .foregroundColor(.white)
            }
            
            HStack {
                DirectSlider(
                    value: $value,
                    range: range,
                    step: step,
                    onChange: onChange,
                    highPriority: highPriority
                )
                .accentColor(sliderColor)
                
                Text(displayText(value))
                    .foregroundColor(.white)
                    .frame(width: 55, alignment: .trailing)
                    .font(.system(.body, design: .monospaced))
            }
        }
        .padding()
        .background(Color.black.opacity(0.2))
        .cornerRadius(12)
    }
}

// MARK: - Preview

struct CustomReverbView_Previews: PreviewProvider {
    static var previews: some View {
        CustomReverbView(audioManager: AudioManager.shared)
            .preferredColorScheme(.dark)
    }
}

=== Reverb/Audio/AudioManager.swift ===
import Foundation
import AVFoundation
import Combine

class AudioManager: ObservableObject {
    static let shared = AudioManager()
    
    // Audio services
    private(set) var audioEngineService: AudioEngineService?
    private var recordingService: RecordingService?
    
    // Published properties
    @Published var selectedReverbPreset: ReverbPreset = .vocalBooth
    @Published var currentAudioLevel: Float = 0.0
    @Published var isRecording: Bool = false
    @Published var lastRecordingFilename: String?
    
    // Custom reverb settings
    @Published var customReverbSettings = CustomReverbSettings.default
    
    // Recording state
    private var currentRecordingPreset: String = ""
    private var recordingStartTime: Date?
    
    // Monitoring state
    private var isMonitoringActive = false
    
    // Preset description
    var currentPresetDescription: String {
        switch selectedReverbPreset {
        case .clean:
            return "Signal audio pur sans traitement"
        case .vocalBooth:
            return "Ambiance feutrée pour la voix parlée"
        case .studio:
            return "Son équilibré pour l'enregistrement"
        case .cathedral:
            return "Réverbération spacieuse et noble"
        case .custom:
            return "Paramètres personnalisables"
        }
    }
    
    private init() {
        setupServices()
    }
    
    private func setupServices() {
        audioEngineService = AudioEngineService()
        audioEngineService?.onAudioLevelChanged = { [weak self] level in
            DispatchQueue.main.async {
                self?.currentAudioLevel = level
            }
        }
        
        // CORRECTION: Passer l'audioEngineService au RecordingService
        recordingService = RecordingService(audioEngineService: audioEngineService)
        
        print("✅ Audio services initialized with engine connection")
    }
    
    // MARK: - Public Methods
    
    func prepareAudio() {
        if audioEngineService == nil {
            setupServices()
        }
        print("🔧 Audio services prepared")
    }
    
    func startMonitoring() {
        guard !isMonitoringActive else {
            print("⚠️ Monitoring already active")
            return
        }
        
        audioEngineService?.setMonitoring(enabled: true)
        audioEngineService?.updateReverbPreset(preset: selectedReverbPreset)
        isMonitoringActive = true
        
        print("✅ Monitoring started with preset: \(selectedReverbPreset.rawValue)")
    }
    
    func stopMonitoring() {
        guard isMonitoringActive else {
            print("⚠️ Monitoring not active")
            return
        }
        
        audioEngineService?.setMonitoring(enabled: false)
        isMonitoringActive = false
        
        if isRecording {
            // Arrêter l'enregistrement si en cours
            stopRecording { _, _, _ in }
        }
        
        print("🔇 Monitoring stopped")
    }
    
    func updateReverbPreset(_ preset: ReverbPreset) {
        selectedReverbPreset = preset
        
        if preset == .custom {
            ReverbPreset.updateCustomSettings(customReverbSettings)
        }
        
        audioEngineService?.updateReverbPreset(preset: preset)
        
        print("🎛️ Reverb preset updated to: \(preset.rawValue)")
    }
    
    // MARK: - Input Volume Control
    
    func setInputVolume(_ volume: Float) {
        audioEngineService?.setInputVolume(volume)
    }
    
    func getInputVolume() -> Float {
        return audioEngineService?.getInputVolume() ?? 0.7
    }
    
    // MARK: - Recording Methods (restent identiques)
    
    func startRecording(completion: @escaping (Bool) -> Void) {
        guard let recordingService = recordingService else {
            print("❌ Recording service not available")
            completion(false)
            return
        }
        
        guard !isRecording else {
            print("⚠️ Recording already in progress")
            completion(false)
            return
        }
        
        guard isMonitoringActive else {
            print("⚠️ Cannot record without active monitoring")
            completion(false)
            return
        }
        
        currentRecordingPreset = selectedReverbPreset.rawValue
        recordingStartTime = Date()
        
        print("🎙️ Starting recording with processed signal (reverb: \(currentRecordingPreset))")
        
        recordingService.startRecording { [weak self] success in
            DispatchQueue.main.async {
                if success {
                    self?.isRecording = true
                    print("✅ Recording started with processed audio (preset: \(self?.currentRecordingPreset ?? "unknown"))")
                } else {
                    print("❌ Failed to start recording")
                    self?.recordingStartTime = nil
                }
                completion(success)
            }
        }
    }
    
    func stopRecording(completion: @escaping (Bool, String?, TimeInterval) -> Void) {
        guard let recordingService = recordingService else {
            print("❌ Recording service not available")
            completion(false, nil, 0)
            return
        }
        
        guard isRecording else {
            print("⚠️ No active recording to stop")
            completion(false, nil, 0)
            return
        }
        
        // Calculer la durée
        let duration = recordingStartTime?.timeIntervalSinceNow.magnitude ?? 0
        
        recordingService.stopRecording { [weak self] success, filename in
            DispatchQueue.main.async {
                self?.isRecording = false
                self?.recordingStartTime = nil
                
                if success {
                    self?.lastRecordingFilename = filename
                    print("✅ Processed recording stopped successfully: \(filename ?? "unknown"), duration: \(duration)s")
                } else {
                    print("❌ Recording stop failed")
                    self?.lastRecordingFilename = self?.generateFallbackFilename()
                }
                
                completion(success, filename, duration)
            }
        }
    }
    
    func toggleRecording() {
        if isRecording {
            stopRecording { success, filename, duration in
                print("Recording toggled off: success=\(success), duration=\(duration)s")
            }
        } else {
            startRecording { success in
                print("Recording toggled on: success=\(success)")
            }
        }
    }
    
    private func generateFallbackFilename() -> String {
        let formatter = DateFormatter()
        formatter.dateFormat = "yyyyMMdd_HHmmss"
        return "recording_\(currentRecordingPreset)_\(formatter.string(from: Date())).m4a"
    }
    
    // MARK: - Custom Reverb Management (reste identique)
    
    func updateCustomReverbSettings(_ settings: CustomReverbSettings) {
        customReverbSettings = settings
        ReverbPreset.updateCustomSettings(settings)
        
        if selectedReverbPreset == .custom {
            audioEngineService?.updateReverbPreset(preset: .custom)
        }
        
        print("🎛️ Custom reverb settings updated")
    }
    
    func resetCustomReverbSettings() {
        customReverbSettings = CustomReverbSettings.default
        ReverbPreset.updateCustomSettings(customReverbSettings)
        
        if selectedReverbPreset == .custom {
            audioEngineService?.updateReverbPreset(preset: .custom)
        }
        
        print("🔄 Custom reverb settings reset to default")
    }
    
    // MARK: - Audio Control Methods (restent identiques)
    
    func setOutputVolume(_ volume: Float, isMuted: Bool) {
        audioEngineService?.setOutputVolume(volume, isMuted: isMuted)
    }
    
    func diagnostic() {
        print("🔍 === AUDIO MANAGER DIAGNOSTIC ===")
        print("- Selected preset: \(selectedReverbPreset.rawValue)")
        print("- Monitoring active: \(isMonitoringActive)")
        print("- Recording active: \(isRecording)")
        print("- Current audio level: \(currentAudioLevel)")
        print("- Audio engine service: \(audioEngineService != nil ? "✅" : "❌")")
        print("- Recording service: \(recordingService != nil ? "✅" : "❌")")
        
        audioEngineService?.diagnosticMonitoring()
        print("=== END AUDIO MANAGER DIAGNOSTIC ===")
    }
    
    // MARK: - Recording Info Methods (restent identiques)
    
    func getCurrentRecordingInfo() -> (preset: String, isActive: Bool, duration: TimeInterval) {
        let duration = recordingStartTime?.timeIntervalSinceNow.magnitude ?? 0
        return (currentRecordingPreset, isRecording, duration)
    }
    
    func getRecordingDuration() -> TimeInterval {
        guard let startTime = recordingStartTime, isRecording else { return 0 }
        return Date().timeIntervalSince(startTime)
    }
    
    // MARK: - State Properties (restent identiques)
    
    var isMonitoring: Bool {
        return isMonitoringActive
    }
    
    var canStartRecording: Bool {
        return isMonitoringActive && !isRecording
    }
    
    var canStartMonitoring: Bool {
        return audioEngineService != nil && !isMonitoringActive
    }
    
    // MARK: - Custom Settings Integration (reste identique)
    
    func updateCustomSetting(
        size: Float? = nil,
        decayTime: Float? = nil,
        preDelay: Float? = nil,
        crossFeed: Float? = nil,
        wetDryMix: Float? = nil,
        density: Float? = nil,
        highFrequencyDamping: Float? = nil,
        applyImmediately: Bool = true
    ) {
        var settings = customReverbSettings
        
        if let size = size { settings.size = size }
        if let decayTime = decayTime { settings.decayTime = decayTime }
        if let preDelay = preDelay { settings.preDelay = preDelay }
        if let crossFeed = crossFeed { settings.crossFeed = crossFeed }
        if let wetDryMix = wetDryMix { settings.wetDryMix = wetDryMix }
        if let density = density { settings.density = density }
        if let highFrequencyDamping = highFrequencyDamping { settings.highFrequencyDamping = highFrequencyDamping }
        
        customReverbSettings = settings
        
        if applyImmediately {
            updateCustomReverbSettings(settings)
        }
    }
}

=== Reverb/Audio/Models/CustomReverbSettings.swift ===
//
//  CustomReverbSettings.swift
//  Reverb
//
//  Created by a on 20/07/2025.
//


=== Reverb/Audio/Models/ReverbPreset.swift ===
import Foundation
import AVFoundation

/// Structure for custom reverb settings
struct CustomReverbSettings {
    var size: Float = 0.82             // 0.0-1.0 (relates to room dimensions)
    var decayTime: Float = 2.0         // 0.1-8.0 seconds
    var preDelay: Float = 75.0         // 0-200 ms
    var crossFeed: Float = 0.5         // 0.0-1.0 (stereo spread)
    var wetDryMix: Float = 35          // 0-100%
    var highFrequencyDamping: Float = 50.0 // 0-100%
    var density: Float = 70.0          // 0-100%
    
    static let `default` = CustomReverbSettings()
}

/// Model for reverb presets optimized for Quranic recitation
enum ReverbPreset: String, CaseIterable, Identifiable {
    // Préréglages optimisés pour la récitation coranique
    case clean = "Clean"          // Voix pure, sans effet
    case vocalBooth = "Vocal Booth" // Légère ambiance, clarté maximale
    case studio = "Studio"        // Ambiance équilibrée, présence harmonieuse
    case cathedral = "Cathedral"    // Réverbération noble et profonde
    case custom = "Personnalisé"    // Paramètres personnalisés par l'utilisateur
    
    var id: String { rawValue }
    
    /// Returns the corresponding AVAudioUnitReverbPreset as base
    var preset: AVAudioUnitReverbPreset {
        switch self {
        case .clean: return .smallRoom
        case .vocalBooth: return .mediumRoom
        case .studio: return .largeRoom
        case .cathedral: return .mediumHall // Ajusté pour plus de stabilité
        case .custom: return .mediumHall    // Base pour paramétrage personnalisé
        }
    }
    
    /// Returns the wet/dry mix value (0-100)
    var wetDryMix: Float {
        switch self {
        case .clean: return 0       // Aucun effet
        case .vocalBooth: return 18   // Subtil mais perceptible
        case .studio: return 40     // Équilibré, présence notable
        case .cathedral: return 65   // Important mais pas excessif pour éviter les saccades
        case .custom: return CustomReverbSettings.default.wetDryMix
        }
    }
    
    /// Returns the decay time in seconds
    var decayTime: Float {
        switch self {
        case .clean: return 0.1
        case .vocalBooth: return 0.9  // Légèrement plus long pour la douceur
        case .studio: return 1.7      // Durée moyenne pour l'intelligibilité
        case .cathedral: return 2.8   // Réduit pour éviter les saccades, reste noble
        case .custom: return CustomReverbSettings.default.decayTime
        }
    }
    
    /// Returns pre-delay in ms (0-100ms)
    var preDelay: Float {
        switch self {
        case .clean: return 0
        case .vocalBooth: return 8     // Clarté des consonnes
        case .studio: return 15        // Séparation naturelle
        case .cathedral: return 25     // Réduit pour éviter les saccades
        case .custom: return CustomReverbSettings.default.preDelay
        }
    }
    
    /// Returns room size (0-100)
    var roomSize: Float {
        switch self {
        case .clean: return 0
        case .vocalBooth: return 35    // Pièce intime
        case .studio: return 60        // Espace confortable
        case .cathedral: return 85     // Grande mais pas maximale pour maintenir la stabilité
        case .custom: return CustomReverbSettings.default.size * 100 // Convert 0-1 to 0-100
        }
    }
    
    /// Returns density value (0-100)
    var density: Float {
        switch self {
        case .clean: return 0
        case .vocalBooth: return 70    // Dense pour éviter le flottement
        case .studio: return 85        // Naturel et riche
        case .cathedral: return 60     // Réduit pour limiter la charge CPU
        case .custom: return CustomReverbSettings.default.density
        }
    }
    
    /// Returns HF damping (0-100) - Contrôle l'absorption des hautes fréquences
    var highFrequencyDamping: Float {
        switch self {
        case .clean: return 0
        case .vocalBooth: return 30    // Conserve la clarté
        case .studio: return 45        // Équilibré
        case .cathedral: return 60     // Plus d'absorption pour limiter les résonances aiguës
        case .custom: return CustomReverbSettings.default.highFrequencyDamping
        }
    }
    
    /// Returns the cross feed value (0-100)
    var crossFeed: Float {
        switch self {
        case .clean: return 0
        case .vocalBooth: return 30    // Stéréo légère
        case .studio: return 50        // Équilibré
        case .cathedral: return 70     // Large espace
        case .custom: return CustomReverbSettings.default.crossFeed * 100 // Convert 0-1 to 0-100
        }
    }
    
    /// Description of how this preset affects recitation
    var description: String {
        switch self {
        case .clean:
            return "Signal pur, fidèle à la voix originale, sans aucun effet."
        case .vocalBooth:
            return "Légère ambiance spatiale qui préserve la clarté et l'intelligibilité de chaque mot."
        case .studio:
            return "Réverbération équilibrée qui enrichit la voix tout en conservant la précision de la récitation."
        case .cathedral:
            return "Profondeur et noblesse qui évoquent l'espace d'un lieu de culte, pour une récitation solennelle."
        case .custom:
            return "Paramètres personnalisés pour créer votre propre environnement acoustique."
        }
    }
}

// MARK: - Extensions pour la gestion des paramètres personnalisés

extension ReverbPreset {
    /// Retourne les paramètres personnalisés avec une source statique
    static var customSettings: CustomReverbSettings = CustomReverbSettings.default
    
    /// Met à jour les paramètres personnalisés
    static func updateCustomSettings(_ settings: CustomReverbSettings) {
        customSettings = settings
    }
    
    /// Version avec paramètres dynamiques
    func values(with customSettings: CustomReverbSettings? = nil) -> (wetDryMix: Float, decayTime: Float, preDelay: Float, roomSize: Float, density: Float, highFrequencyDamping: Float, crossFeed: Float) {
        let settings = customSettings ?? ReverbPreset.customSettings
        
        switch self {
        case .clean:
            return (0, 0.1, 0, 0, 0, 0, 0)
        case .vocalBooth:
            return (18, 0.9, 8, 35, 70, 30, 30)
        case .studio:
            return (40, 1.7, 15, 60, 85, 45, 50)
        case .cathedral:
            return (65, 2.8, 25, 85, 60, 60, 70)
        case .custom:
            return (settings.wetDryMix, settings.decayTime, settings.preDelay, settings.size * 100, settings.density, settings.highFrequencyDamping, settings.crossFeed * 100)
        }
    }
}

=== Reverb/Audio/Services/RecordingService.swift ===
import Foundation
import AVFoundation

class RecordingService: NSObject {
    private var audioPlayer: AVAudioPlayer?
    
    #if os(iOS)
    private var recordingSession: AVAudioSession?
    #endif
    
    private var currentRecordingURL: URL?
    private var isCurrentlyRecording = false
    private var isCurrentlyPlaying = false
    
    // CORRECTION: Simplification pour éviter les crashes
    private weak var audioEngineService: AudioEngineService?
    private var recordingFile: AVAudioFile?
    private var tapNode: AVAudioNode?
    private var recordingQueue: DispatchQueue
    
    // Format management
    enum RecordingFormat: String, CaseIterable {
        case wav = "wav"
        case mp3 = "mp3"
        case aac = "aac"
        
        var displayName: String {
            switch self {
            case .wav: return "WAV (Qualité maximale)"
            case .mp3: return "MP3 (Ultra-compatible)"
            case .aac: return "AAC (Équilibré)"
            }
        }
        
        var fileExtension: String {
            return self.rawValue
        }
    }
    
    private var selectedFormat: RecordingFormat = .wav
    private var recordingDirectory: URL
    
    init(audioEngineService: AudioEngineService? = nil) {
        let documentsDir = RecordingService.getDocumentsDirectory()
        let recordingsDir = documentsDir.appendingPathComponent("Recordings")
        
        // Créer la queue d'enregistrement pour thread safety
        recordingQueue = DispatchQueue(label: "com.audio.recording", qos: .userInitiated)
        
        if !FileManager.default.fileExists(atPath: recordingsDir.path) {
            do {
                try FileManager.default.createDirectory(at: recordingsDir, withIntermediateDirectories: true)
                print("✅ Created Recordings directory")
            } catch {
                print("❌ Failed to create Recordings directory: \(error)")
            }
        }
        
        recordingDirectory = recordingsDir
        self.audioEngineService = audioEngineService
        super.init()
        setupRecordingSession()
        
        print("🎵 Recording service initialized with crash protection")
    }
    
    // MARK: - Format Management
    
    func setRecordingFormat(_ format: RecordingFormat) {
        selectedFormat = format
        print("🎵 Recording format changed to: \(format.displayName)")
    }
    
    func getCurrentFormat() -> RecordingFormat {
        return selectedFormat
    }
    
    func getAllFormats() -> [RecordingFormat] {
        return RecordingFormat.allCases
    }
    
    // MARK: - Setup
    
    private func setupRecordingSession() {
        #if os(iOS)
        recordingSession = AVAudioSession.sharedInstance()
        
        do {
            try recordingSession?.setCategory(.playAndRecord, mode: .default)
            try recordingSession?.setActive(true)
            print("✅ Recording session configured for iOS")
        } catch {
            print("❌ Failed to setup recording session: \(error)")
        }
        #else
        print("🍎 macOS recording session ready - no AVAudioSession needed")
        #endif
    }
    
    // MARK: - Recording Methods SÉCURISÉS
    
    func startRecording(completion: @escaping (Bool) -> Void) {
        // PROTECTION 1: Vérifier l'état
        guard !isCurrentlyRecording else {
            print("⚠️ Recording already in progress")
            DispatchQueue.main.async {
                completion(false)
            }
            return
        }
        
        // PROTECTION 2: Vérifier les services disponibles
        guard let audioEngineService = audioEngineService else {
            print("❌ AudioEngineService not available")
            DispatchQueue.main.async {
                completion(false)
            }
            return
        }
        
        // PROTECTION 3: Vérifier que l'engine fonctionne
        guard let recordingMixer = audioEngineService.getRecordingMixer(),
              let engineFormat = audioEngineService.getRecordingFormat() else {
            print("❌ AudioEngine components not ready")
            DispatchQueue.main.async {
                completion(false)
            }
            return
        }
        
        let filename = generateUniqueFilename()
        currentRecordingURL = recordingDirectory.appendingPathComponent(filename)
        
        guard let recordingURL = currentRecordingURL else {
            print("❌ Could not create recording URL")
            DispatchQueue.main.async {
                completion(false)
            }
            return
        }
        
        print("🎙️ Starting SAFE processed recording to: \(recordingURL.path)")
        
        // PROTECTION 4: Exécuter dans une queue dédiée
        recordingQueue.async { [weak self] in
            self?.startSafeProcessedRecording(
                recordingMixer: recordingMixer,
                format: engineFormat,
                url: recordingURL,
                completion: completion
            )
        }
    }
    
    // NOUVEAU: Enregistrement sécurisé avec protection contre les crashes
    private func startSafeProcessedRecording(recordingMixer: AVAudioMixerNode, format: AVAudioFormat, url: URL, completion: @escaping (Bool) -> Void) {
        
        print("🔒 Starting SAFE processed audio recording")
        
        // PROTECTION 1: Nettoyer avant de commencer
        cleanupRecording()
        
        do {
            // PROTECTION 2: Créer un format simple et compatible
            let recordingFormat = createSafeRecordingFormat(basedOn: format)
            
            print("📊 Safe recording format: \(recordingFormat.sampleRate) Hz, \(recordingFormat.channelCount) channels")
            print("🎵 Format type: \(recordingFormat.commonFormat.rawValue)")
            
            // PROTECTION 3: Créer le fichier avec try-catch robuste
            recordingFile = try AVAudioFile(forWriting: url, settings: recordingFormat.settings)
            
            guard let audioFile = recordingFile else {
                print("❌ Could not create audio file")
                DispatchQueue.main.async { completion(false) }
                return
            }
            
            print("✅ Safe audio file created")
            
            // PROTECTION 4: Vérifier que le mixer est prêt avant d'installer le tap
            guard recordingMixer.engine != nil else {
                print("❌ Recording mixer not attached to engine")
                DispatchQueue.main.async { completion(false) }
                return
            }
            
            // PROTECTION 5: Installer le tap avec gestion d'erreur complète
            do {
                recordingMixer.installTap(onBus: 0, bufferSize: 4096, format: recordingFormat) { [weak self] buffer, time in
                    // PROTECTION 6: Vérifications dans le tap
                    guard let self = self,
                          self.isCurrentlyRecording,
                          let audioFile = self.recordingFile else {
                        return
                    }
                    
                    // PROTECTION 7: Écriture thread-safe
                    do {
                        try audioFile.write(from: buffer)
                        
                        // Debug périodique
                        if Int.random(in: 0...1000) == 0 {
                            print("🔄 Safe recording: \(buffer.frameLength) frames")
                        }
                    } catch {
                        print("⚠️ Buffer write error (non-fatal): \(error)")
                        // Ne pas crasher pour une erreur d'écriture
                    }
                }
                
                // PROTECTION 8: Marquer comme en cours seulement si tout a réussi
                isCurrentlyRecording = true
                tapNode = recordingMixer
                
                print("✅ Safe processed recording started successfully")
                DispatchQueue.main.async { completion(true) }
                
            } catch {
                print("❌ Failed to install safe tap: \(error)")
                cleanupRecording()
                DispatchQueue.main.async { completion(false) }
            }
            
        } catch {
            print("❌ Safe recording setup failed: \(error.localizedDescription)")
            cleanupRecording()
            DispatchQueue.main.async { completion(false) }
        }
    }
    
    // NOUVEAU: Format d'enregistrement ultra-sécurisé
    private func createSafeRecordingFormat(basedOn sourceFormat: AVAudioFormat) -> AVAudioFormat {
        let sampleRate = sourceFormat.sampleRate
        let channels = min(sourceFormat.channelCount, 2) // Limiter à stéréo maximum
        
        // PROTECTION: Toujours utiliser Float32 pour éviter les problèmes de conversion
        let safeFormat = AVAudioFormat(
            commonFormat: .pcmFormatFloat32,
            sampleRate: sampleRate,
            channels: channels,
            interleaved: false
        )
        
        if let safeFormat = safeFormat {
            print("✅ Created safe format: \(safeFormat)")
            return safeFormat
        } else {
            // FALLBACK: Format de base garanti
            print("⚠️ Using fallback format")
            return AVAudioFormat(standardFormatWithSampleRate: 44100, channels: 2)!
        }
    }
    
    func stopRecording(completion: @escaping (Bool, String?) -> Void) {
        print("🛑 Stopping safe recording...")
        
        // PROTECTION 1: Vérifier l'état
        guard isCurrentlyRecording else {
            print("⚠️ No active recording to stop")
            DispatchQueue.main.async { completion(false, nil) }
            return
        }
        
        let filename = currentRecordingURL?.lastPathComponent
        isCurrentlyRecording = false // Arrêter immédiatement pour éviter les écritures
        
        // PROTECTION 2: Exécuter dans la queue d'enregistrement
        recordingQueue.async { [weak self] in
            self?.stopSafeRecording(filename: filename, completion: completion)
        }
    }
    
    // NOUVEAU: Arrêt sécurisé
    private func stopSafeRecording(filename: String?, completion: @escaping (Bool, String?) -> Void) {
        
        // PROTECTION 1: Arrêter le tap de manière sécurisée
        if let tapNode = tapNode as? AVAudioMixerNode {
            do {
                tapNode.removeTap(onBus: 0)
                print("✅ Tap removed safely")
            } catch {
                print("⚠️ Error removing tap (non-fatal): \(error)")
            }
            self.tapNode = nil
        }
        
        // PROTECTION 2: Finaliser le fichier de manière sécurisée
        if let audioFile = recordingFile {
            recordingFile = nil // Finalise automatiquement
            print("💾 Audio file finalized safely")
        }
        
        // PROTECTION 3: Attendre la finalisation
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) { [weak self] in
            self?.verifySafeRecording(filename: filename, completion: completion)
        }
    }
    
    // NOUVEAU: Vérification sécurisée
    private func verifySafeRecording(filename: String?, completion: @escaping (Bool, String?) -> Void) {
        guard let url = currentRecordingURL else {
            print("❌ No recording URL")
            completion(false, nil)
            return
        }
        
        // PROTECTION: Vérifications avec try-catch
        do {
            guard FileManager.default.fileExists(atPath: url.path) else {
                print("❌ Recording file not found")
                completion(false, nil)
                return
            }
            
            let attributes = try FileManager.default.attributesOfItem(atPath: url.path)
            let fileSize = attributes[.size] as? Int64 ?? 0
            
            print("📁 Safe recording file size: \(formatFileSize(fileSize))")
            
            if fileSize > 4096 { // Minimum 4KB pour un fichier valide
                print("✅ Safe recording completed: \(filename ?? "unknown")")
                cleanupRecording()
                completion(true, filename)
            } else {
                print("⚠️ Recording file too small: \(fileSize) bytes")
                cleanupRecording()
                completion(false, nil)
            }
            
        } catch {
            print("❌ Error verifying recording: \(error)")
            cleanupRecording()
            completion(false, nil)
        }
    }
    
    // MARK: - Playback Methods (simplifiés pour éviter les crashes)
    
    func playRecording(at url: URL, completion: @escaping (Bool) -> Void) {
        print("🎬 Starting SAFE playback: \(url.lastPathComponent)")
        
        // PROTECTION: Arrêter proprement toute lecture en cours
        stopPlayback()
        
        // PROTECTION: Vérifications préalables
        guard FileManager.default.fileExists(atPath: url.path) else {
            print("❌ File not found")
            completion(false)
            return
        }
        
        do {
            // PROTECTION: Créer le player avec try-catch
            audioPlayer = try AVAudioPlayer(contentsOf: url)
            
            guard let player = audioPlayer else {
                print("❌ Failed to create player")
                completion(false)
                return
            }
            
            // PROTECTION: Configuration sécurisée
            player.delegate = self
            player.volume = 1.0
            
            // PROTECTION: Préparation avec vérification
            guard player.prepareToPlay() else {
                print("❌ Failed to prepare player")
                audioPlayer = nil
                completion(false)
                return
            }
            
            // PROTECTION: Lancement avec vérification
            let success = player.play()
            isCurrentlyPlaying = success
            
            if success {
                print("▶️ Safe playback started")
                completion(true)
            } else {
                print("❌ Failed to start playback")
                audioPlayer = nil
                completion(false)
            }
            
        } catch {
            print("❌ Playback error: \(error.localizedDescription)")
            audioPlayer = nil
            completion(false)
        }
    }
    
    func stopPlayback() {
        if let player = audioPlayer {
            if player.isPlaying {
                player.stop()
            }
            audioPlayer = nil
        }
        isCurrentlyPlaying = false
        print("⏹️ Playback stopped safely")
    }
    
    func pausePlayback() {
        guard let player = audioPlayer, isCurrentlyPlaying else { return }
        player.pause()
        isCurrentlyPlaying = false
        print("⏸️ Playback paused")
    }
    
    func resumePlayback() -> Bool {
        guard let player = audioPlayer else { return false }
        let success = player.play()
        isCurrentlyPlaying = success
        return success
    }
    
    // MARK: - Cleanup sécurisé
    
    private func cleanupRecording() {
        // PROTECTION: Nettoyage dans l'ordre correct
        if let tapNode = tapNode as? AVAudioMixerNode {
            do {
                tapNode.removeTap(onBus: 0)
            } catch {
                print("⚠️ Tap cleanup error (ignored): \(error)")
            }
            self.tapNode = nil
        }
        
        recordingFile = nil
        print("🧹 Safe cleanup completed")
    }
    
    // MARK: - File Management
    
    func getAllRecordings() -> [URL] {
        do {
            let files = try FileManager.default.contentsOfDirectory(
                at: recordingDirectory,
                includingPropertiesForKeys: [.creationDateKey, .fileSizeKey]
            )
            
            let validRecordings = files.filter { url in
                let ext = url.pathExtension.lowercased()
                let isValidFormat = ["wav", "mp3", "aac"].contains(ext)
                
                if let resourceValues = try? url.resourceValues(forKeys: [.fileSizeKey]),
                   let fileSize = resourceValues.fileSize {
                    return isValidFormat && fileSize > 4096 // 4KB minimum
                }
                
                return isValidFormat
            }
            
            return validRecordings.sorted { url1, url2 in
                let date1 = (try? url1.resourceValues(forKeys: [.creationDateKey]))?.creationDate ?? Date.distantPast
                let date2 = (try? url2.resourceValues(forKeys: [.creationDateKey]))?.creationDate ?? Date.distantPast
                return date1 > date2
            }
            
        } catch {
            print("❌ Error reading recordings: \(error)")
            return []
        }
    }
    
    // MARK: - Helper Methods
    
    private func generateUniqueFilename() -> String {
        let formatter = DateFormatter()
        formatter.dateFormat = "yyyyMMdd_HHmmss"
        let timestamp = formatter.string(from: Date())
        return "safe_reverb_\(timestamp).\(selectedFormat.fileExtension)"
    }
    
    static func getDocumentsDirectory() -> URL {
        let paths = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)
        return paths[0]
    }
    
    private func formatFileSize(_ bytes: Int64) -> String {
        let formatter = ByteCountFormatter()
        formatter.allowedUnits = [.useKB, .useMB]
        formatter.countStyle = .file
        return formatter.string(fromByteCount: bytes)
    }
    
    func getRecordingInfo(for url: URL) -> (duration: TimeInterval, fileSize: Int64, creationDate: Date)? {
        do {
            let asset = AVURLAsset(url: url)
            let duration = CMTimeGetSeconds(asset.duration)
            
            let attributes = try FileManager.default.attributesOfItem(atPath: url.path)
            let fileSize = attributes[.size] as? Int64 ?? 0
            let creationDate = attributes[.creationDate] as? Date ?? Date()
            
            let validDuration = duration.isFinite && duration > 0 ? duration : 0
            
            return (duration: validDuration, fileSize: fileSize, creationDate: creationDate)
        } catch {
            print("❌ Error getting recording info: \(error)")
            return nil
        }
    }
    
    func deleteRecording(at url: URL, completion: @escaping (Bool) -> Void) {
        if let playerURL = audioPlayer?.url, playerURL == url {
            stopPlayback()
        }
        
        do {
            try FileManager.default.removeItem(at: url)
            print("✅ Recording deleted: \(url.lastPathComponent)")
            completion(true)
        } catch {
            print("❌ Failed to delete: \(error)")
            completion(false)
        }
    }
    
    // MARK: - Properties
    
    var isPlaying: Bool {
        return isCurrentlyPlaying && (audioPlayer?.isPlaying ?? false)
    }
    
    var isRecording: Bool {
        return isCurrentlyRecording
    }
    
    var currentPlaybackTime: TimeInterval {
        return audioPlayer?.currentTime ?? 0
    }
    
    var playbackDuration: TimeInterval {
        return audioPlayer?.duration ?? 0
    }
    
    deinit {
        print("🗑️ Cleaning up RecordingService...")
        cleanupRecording()
        stopPlayback()
    }
}

// MARK: - Delegates

extension RecordingService: AVAudioPlayerDelegate {
    
    func audioPlayerDidFinishPlaying(_ player: AVAudioPlayer, successfully flag: Bool) {
        print("▶️ Playback finished: success=\(flag)")
        isCurrentlyPlaying = false
    }
    
    func audioPlayerDecodeErrorDidOccur(_ player: AVAudioPlayer, error: Error?) {
        print("❌ Player decode error: \(error?.localizedDescription ?? "unknown")")
        isCurrentlyPlaying = false
        stopPlayback()
    }
}

=== Reverb/Audio/Services/AudioEngineService.swift ===
import Foundation
import AVFoundation
import AudioToolbox

class AudioEngineService {
    // Audio engine components
    private var audioEngine: AVAudioEngine?
    private var inputNode: AVAudioInputNode?
    private var mainMixer: AVAudioMixerNode?
    private var reverbNode: AVAudioUnitReverb?
    
    // CORRECTION: Chaîne simplifiée pour qualité optimale
    private var recordingMixer: AVAudioMixerNode?
    private var gainMixer: AVAudioMixerNode?          // Un seul étage de gain optimal
    private var cleanBypassMixer: AVAudioMixerNode?   // Bypass direct pour mode Clean
    
    // Advanced components for stereo effects
    private var stereoMixerL: AVAudioMixerNode?
    private var stereoMixerR: AVAudioMixerNode?
    private var delayNode: AVAudioUnitDelay?
    private var crossFeedEnabled = false
    
    // Engine state
    private var isEngineRunning = false
    private var setupAttempts = 0
    private let maxSetupAttempts = 3
    private var currentPreset: ReverbPreset = .clean
    
    // Format de connexion unifié
    private var connectionFormat: AVAudioFormat?
    
    // CORRECTION: Volumes optimaux pour qualité
    private var inputVolume: Float = 1.0    // Volume modéré par défaut
    private var monitoringGain: Float = 1.2 // Gain raisonnable
    
    // Callbacks
    var onAudioLevelChanged: ((Float) -> Void)?
    
    init() {
        setupAudioSession()
        setupAudioEngine()
    }
    
    // MARK: - Configuration optimisée
    
    private func setupAudioSession() {
        #if os(iOS)
        do {
            let session = AVAudioSession.sharedInstance()
            try session.setCategory(
                .playAndRecord,
                mode: .default,
                options: [.defaultToSpeaker, .allowBluetooth, .mixWithOthers]
            )
            try session.setActive(true)
            
            // CORRECTION: Configuration équilibrée pour qualité
            try session.setPreferredSampleRate(44100)
            try session.setPreferredIOBufferDuration(0.01) // Buffer plus stable
            try session.setPreferredInputNumberOfChannels(2)
            try session.setInputGain(0.8) // Gain système modéré
            
            print("✅ AVAudioSession configured for QUALITY monitoring")
        } catch {
            print("❌ Audio session configuration error: \(error.localizedDescription)")
        }
        #else
        print("🍎 macOS audio session ready for QUALITY amplification")
        requestMicrophonePermission()
        #endif
    }
    
    #if os(macOS)
    private func requestMicrophonePermission() {
        let micAccess = AVCaptureDevice.authorizationStatus(for: .audio)
        print("🎤 Microphone authorization status: \(micAccess.rawValue)")
        
        if micAccess == .notDetermined {
            AVCaptureDevice.requestAccess(for: .audio) { granted in
                DispatchQueue.main.async {
                    print("🎤 Microphone access granted: \(granted)")
                    if granted {
                        self.setupAudioEngine()
                    }
                }
            }
        }
    }
    #endif
    
    private func setupAudioEngine() {
        guard setupAttempts < maxSetupAttempts else {
            print("❌ Maximum setup attempts reached")
            return
        }
         
        setupAttempts += 1
        print("🎵 Setting up QUALITY-OPTIMIZED audio engine (attempt \(setupAttempts))")
        
        cleanupEngine()
        
        let engine = AVAudioEngine()
        audioEngine = engine
        
        let inputNode = engine.inputNode
        self.inputNode = inputNode
        let mainMixer = engine.mainMixerNode
        mainMixer.outputVolume = 1.4 // Gain modéré pour qualité
        self.mainMixer = mainMixer
        
        // CORRECTION: Chaîne simplifiée pour éviter la dégradation
        let gainMixer = AVAudioMixerNode()
        gainMixer.outputVolume = 1.3 // Gain équilibré
        self.gainMixer = gainMixer
        engine.attach(gainMixer)
        
        // NOUVEAU: Bypass direct pour mode Clean
        let cleanBypassMixer = AVAudioMixerNode()
        cleanBypassMixer.outputVolume = 1.2 // Gain léger pour bypass
        self.cleanBypassMixer = cleanBypassMixer
        engine.attach(cleanBypassMixer)
        
        // Configuration du reverb optimisée
        let reverb = AVAudioUnitReverb()
        reverb.loadFactoryPreset(.smallRoom)
        reverb.wetDryMix = 0 // Désactivé par défaut
        reverbNode = reverb
        engine.attach(reverb)
        
        // Recording mixer pour l'enregistrement
        let recordingMixer = AVAudioMixerNode()
        recordingMixer.outputVolume = 1.0 // Pas d'amplification excessive pour l'enregistrement
        self.recordingMixer = recordingMixer
        engine.attach(recordingMixer)
        
        // Configuration des effets stéréo
        let stereoMixerL = AVAudioMixerNode()
        let stereoMixerR = AVAudioMixerNode()
        let delayNode = AVAudioUnitDelay()
        
        engine.attach(stereoMixerL)
        engine.attach(stereoMixerR)
        engine.attach(delayNode)
        
        self.stereoMixerL = stereoMixerL
        self.stereoMixerR = stereoMixerR
        self.delayNode = delayNode
        
        delayNode.delayTime = 0.01
        delayNode.feedback = 0
        delayNode.wetDryMix = 100
        
        let inputHWFormat = inputNode.inputFormat(forBus: 0)
        print("🎤 Input format: \(inputHWFormat.sampleRate) Hz, \(inputHWFormat.channelCount) channels")
        
        guard inputHWFormat.sampleRate > 0 && inputHWFormat.channelCount > 0 else {
            print("❌ Invalid input format detected")
            if setupAttempts < maxSetupAttempts {
                DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                    self.setupAudioSession()
                    self.setupAudioEngine()
                }
            }
            return
        }
        
        let stereoFormat = AVAudioFormat(standardFormatWithSampleRate: inputHWFormat.sampleRate, channels: 2)!
        self.connectionFormat = stereoFormat
        print("🔗 QUALITY format: \(stereoFormat.sampleRate) Hz, \(stereoFormat.channelCount) channels")
        
        do {
            // CORRECTION CRITIQUE: Chaîne optimale pour qualité
            // Input → GainMixer → (Reverb OU CleanBypass) → RecordingMixer → MainMixer → Output
            
            try engine.connect(inputNode, to: gainMixer, format: stereoFormat)
            
            // Connexions conditionnelles selon le preset (sera configuré dans updateReverbPreset)
            try engine.connect(gainMixer, to: cleanBypassMixer, format: stereoFormat) // Connexion par défaut
            try engine.connect(cleanBypassMixer, to: recordingMixer, format: stereoFormat)
            try engine.connect(recordingMixer, to: mainMixer, format: stereoFormat)
            try engine.connect(mainMixer, to: engine.outputNode, format: nil)
            
            engine.prepare()
            print("🎵 QUALITY-OPTIMIZED audio engine configured successfully")
            print("📊 Theoretical gain: Input × Gain(1.3) × Main(1.4) = x1.8 (optimal)")
            setupAttempts = 0
        } catch {
            print("❌ Quality audio connection error: \(error.localizedDescription)")
            
            if setupAttempts < maxSetupAttempts {
                DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                    self.setupSimplifiedEngine()
                }
            }
        }
    }
    
    // MARK: - Accès au mixer d'enregistrement
    
    func getRecordingMixer() -> AVAudioMixerNode? {
        return recordingMixer
    }
    
    func getRecordingFormat() -> AVAudioFormat? {
        return connectionFormat
    }
    
    // MARK: - Input Volume Control OPTIMISÉ
    
    func setInputVolume(_ volume: Float) {
        // CORRECTION: Amplification raisonnable pour qualité
        let optimizedVolume = max(0.1, min(3.0, volume * 0.8)) // Range modéré 0.1-2.4
        inputVolume = optimizedVolume
        
        // Application équilibrée sur les composants
        inputNode?.volume = optimizedVolume
        gainMixer?.volume = max(1.0, optimizedVolume * 0.7) // Gain proportionnel modéré
        
        print("🎵 QUALITY input volume applied:")
        print("   - Raw volume: \(volume)")
        print("   - Optimized volume: \(optimizedVolume) (\(Int(optimizedVolume * 100))%)")
        print("   - Gain mixer: \(max(1.0, optimizedVolume * 0.7)) (\(Int(max(1.0, optimizedVolume * 0.7) * 100))%)")
    }
    
    func getInputVolume() -> Float {
        return inputVolume
    }
    
    // MARK: - Output Volume Control OPTIMISÉ
    
    func setOutputVolume(_ volume: Float, isMuted: Bool) {
        if isMuted {
            mainMixer?.outputVolume = 0.0
            return
        }
        
        // CORRECTION: Amplification équilibrée pour monitoring de qualité
        let optimizedOutput = max(0.0, min(2.5, volume * 0.9)) // Range modéré 0-2.25
        monitoringGain = optimizedOutput
        
        // Application sur le mixer principal
        mainMixer?.outputVolume = isEngineRunning ? optimizedOutput : 0.0
        
        print("🔊 QUALITY output volume applied:")
        print("   - Raw volume: \(volume)")
        print("   - Optimized output: \(optimizedOutput) (\(Int(optimizedOutput * 100))%)")
        print("   - Total theoretical gain: x\(String(format: "%.1f", optimizedOutput * max(1.0, inputVolume * 0.7)))")
    }
    
    // MARK: - Reverb Preset Management CORRIGÉ
    
    func updateReverbPreset(preset: ReverbPreset) {
        guard let engine = audioEngine,
              let reverb = reverbNode,
              let gainMixer = gainMixer,
              let cleanBypass = cleanBypassMixer,
              let recordingMixer = recordingMixer else {
            print("❌ Audio engine components not available")
            return
        }
        
        currentPreset = preset
        
        print("🎛️ Switching to preset: \(preset.rawValue)")
        
        do {
            // CORRECTION MAJEURE: Reconfiguration complète de la chaîne selon le preset
            
            // Déconnecter toutes les connexions existantes
            engine.disconnectNodeOutput(gainMixer)
            engine.disconnectNodeInput(recordingMixer)
            
            if preset == .clean {
                // MODE CLEAN: Bypass complet du reverb
                print("🎤 CLEAN MODE: Direct bypass without reverb")
                reverb.wetDryMix = 0 // Assurer que le reverb est totalement coupé
                reverb.bypass = true // Bypass complet
                
                // Connexion directe sans reverb
                try engine.connect(gainMixer, to: cleanBypass, format: connectionFormat)
                try engine.connect(cleanBypass, to: recordingMixer, format: connectionFormat)
                
            } else {
                // MODE REVERB: Passage par le reverb
                print("🎵 REVERB MODE: \(preset.rawValue)")
                reverb.bypass = false // Activer le reverb
                reverb.loadFactoryPreset(preset.preset)
                
                let targetWetDryMix = max(0, min(100, preset.wetDryMix))
                reverb.wetDryMix = targetWetDryMix
                
                // Connexion via reverb
                try engine.connect(gainMixer, to: reverb, format: connectionFormat)
                try engine.connect(reverb, to: recordingMixer, format: connectionFormat)
                
                applyAdvancedParameters(to: reverb, preset: preset)
            }
            
            print("✅ Preset '\(preset.rawValue)' applied successfully")
            
        } catch {
            print("❌ Error switching preset: \(error.localizedDescription)")
            
            // Fallback: restaurer connexion de base
            do {
                try engine.connect(gainMixer, to: cleanBypass, format: connectionFormat)
                try engine.connect(cleanBypass, to: recordingMixer, format: connectionFormat)
                reverb.wetDryMix = 0
                reverb.bypass = true
            } catch {
                print("❌ Fallback connection failed: \(error)")
            }
        }
    }
    
    // MARK: - Installation du tap optimisé pour qualité
    
    private func installAudioTap(inputNode: AVAudioInputNode, bufferSize: UInt32) {
        inputNode.removeTap(onBus: 0)
        Thread.sleep(forTimeInterval: 0.01)
        
        guard let tapFormat = connectionFormat else {
            print("❌ No connection format available for tap")
            return
        }
        
        print("🎤 Installing QUALITY-OPTIMIZED tap with format: \(tapFormat)")
        
        do {
            // CORRECTION: Buffer plus grand pour éviter les saccades
            let qualityBufferSize = max(bufferSize, 2048)
            
            inputNode.installTap(onBus: 0, bufferSize: qualityBufferSize, format: tapFormat) { [weak self] buffer, time in
                guard let self = self else { return }
                
                guard let channelData = buffer.floatChannelData else {
                    return
                }
                
                let frameLength = Int(buffer.frameLength)
                guard frameLength > 0 else { return }
                
                let channelCount = Int(buffer.format.channelCount)
                var totalLevel: Float = 0
                
                for channel in 0..<channelCount {
                    let channelPtr = channelData[channel]
                    var sum: Float = 0
                    var maxValue: Float = 0
                    
                    let stride = max(1, frameLength / 32) // Échantillonnage plus précis
                    var sampleCount = 0
                    
                    for i in Swift.stride(from: 0, to: frameLength, by: stride) {
                        let sample = abs(channelPtr[i])
                        sum += sample
                        maxValue = max(maxValue, sample)
                        sampleCount += 1
                    }
                    
                    let avgLevel = sum / Float(max(sampleCount, 1))
                    let channelLevel = max(avgLevel, maxValue * 0.6)
                    totalLevel += channelLevel
                }
                
                let finalLevel = totalLevel / Float(channelCount)
                
                // CORRECTION: Niveau affiché réaliste et stable
                let displayLevel = min(1.0, max(0, finalLevel * self.getOptimalGainFactor()))
                
                if displayLevel > 0.001 && Int.random(in: 0...500) == 0 {
                    print("🎵 Quality Audio: level=\(displayLevel), preset=\(self.currentPreset.rawValue)")
                }
                
                DispatchQueue.main.async {
                    self.onAudioLevelChanged?(displayLevel)
                }
            }
            print("✅ Quality-optimized audio tap installed successfully")
        } catch {
            print("❌ Failed to install quality audio tap: \(error)")
        }
    }
    
    // NOUVEAU: Calcul du gain optimal pour qualité
    private func getOptimalGainFactor() -> Float {
        let inputGain = max(1.0, inputVolume)
        let gainMixerLevel = max(1.0, (gainMixer?.volume ?? 1.0))
        let mainMixerLevel = max(1.0, (mainMixer?.outputVolume ?? 1.0))
        
        // Gain total équilibré pour qualité
        return min(6.0, inputGain * gainMixerLevel * mainMixerLevel)
    }
    
    // MARK: - Monitoring Control avec qualité optimisée
    
    func setMonitoring(enabled: Bool) {
        if enabled {
            startMonitoring()
        } else {
            stopMonitoring()
        }
    }
    
    private func startMonitoring() {
        guard let engine = audioEngine else {
            print("❌ Audio engine not available")
            return
        }
        
        if engine.isRunning {
            engine.stop()
            print("🔄 Engine stopped for quality restart")
            Thread.sleep(forTimeInterval: 0.1)
        }
        
        let success = startEngine()
        
        if success {
            // Application des volumes optimaux
            mainMixer?.outputVolume = 1.4
            recordingMixer?.outputVolume = 1.0
            gainMixer?.volume = 1.3
            cleanBypassMixer?.volume = 1.2
            
            setInputVolume(inputVolume)
            
            // S'assurer que le preset actuel est appliqué correctement
            updateReverbPreset(preset: currentPreset)
            
            print("🎵 QUALITY monitoring started successfully")
            print("📊 Optimal gain: x\(getOptimalGainFactor())")
            
            DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                self.verifyAudioFlow()
            }
        } else {
            print("❌ Failed to start quality monitoring")
        }
    }
    
    private func stopMonitoring() {
        stopEngine()
        print("🔇 Quality monitoring disabled")
    }
    
    private func verifyAudioFlow() {
        guard let engine = audioEngine,
              let reverb = reverbNode,
              let mixer = mainMixer,
              let recMixer = recordingMixer,
              let gainMix = gainMixer,
              let cleanMix = cleanBypassMixer else {
            return
        }
        
        print("🔍 QUALITY AUDIO FLOW VERIFICATION:")
        print("- Engine running: \(engine.isRunning)")
        print("- Current preset: \(currentPreset.rawValue)")
        print("- Reverb bypass: \(reverb.bypass)")
        print("- Reverb wetDryMix: \(reverb.wetDryMix)")
        print("- Input volume: \(inputNode?.volume ?? 0) (\(Int((inputNode?.volume ?? 0) * 100))%)")
        print("- Gain mixer: \(gainMix.volume) (\(Int(gainMix.volume * 100))%)")
        print("- Clean bypass: \(cleanMix.volume) (\(Int(cleanMix.volume * 100))%)")
        print("- Main mixer: \(mixer.outputVolume) (\(Int(mixer.outputVolume * 100))%)")
        print("- Recording mixer: \(recMixer.outputVolume) (\(Int(recMixer.outputVolume * 100))%)")
        print("- OPTIMAL TOTAL GAIN: x\(getOptimalGainFactor())")
        print("- Connection format: \(connectionFormat?.description ?? "none")")
    }
    
    // MARK: - Engine Control optimisé
    
    func startEngine() -> Bool {
        guard let engine = audioEngine, !isEngineRunning else {
            return isEngineRunning
        }
        
        do {
            #if os(iOS)
            try AVAudioSession.sharedInstance().setActive(true)
            #endif
            
            print("🎵 Starting QUALITY-OPTIMIZED audio engine...")
            
            try engine.start()
            isEngineRunning = true
            
            Thread.sleep(forTimeInterval: 0.1)
            
            // Application des volumes optimaux
            if let mixer = mainMixer {
                mixer.outputVolume = 1.4
            }
            
            if let recMixer = recordingMixer {
                recMixer.outputVolume = 1.0
            }
            
            if let gainMix = gainMixer {
                gainMix.volume = 1.3
            }
            
            if let cleanMix = cleanBypassMixer {
                cleanMix.volume = 1.2
            }
            
            if let inputNode = self.inputNode {
                installAudioTap(inputNode: inputNode, bufferSize: 2048) // Buffer plus stable
            }
            
            print("🎵 Quality-optimized engine started successfully")
            return true
            
        } catch {
            let nsError = error as NSError
            print("❌ Quality engine start error: \(error.localizedDescription)")
            print("   Error code: \(nsError.code)")
            
            isEngineRunning = false
            return false
        }
    }
    
    func stopEngine() {
        if let engine = audioEngine, engine.isRunning {
            if let inputNode = self.inputNode {
                inputNode.removeTap(onBus: 0)
            }
            engine.stop()
            isEngineRunning = false
            print("🛑 Quality audio engine stopped")
        }
        setupAttempts = 0
    }
    
    private func cleanupEngine() {
        if let oldEngine = audioEngine, oldEngine.isRunning {
            if let inputNode = self.inputNode {
                inputNode.removeTap(onBus: 0)
            }
            oldEngine.stop()
        }
        isEngineRunning = false
    }
    
    // MARK: - Configuration simplifiée en fallback
    
    private func setupSimplifiedEngine() {
        print("⚠️ Using simplified QUALITY configuration...")
        
        cleanupEngine()
        
        let engine = AVAudioEngine()
        audioEngine = engine
        
        let inputNode = engine.inputNode
        self.inputNode = inputNode
        let mainMixer = engine.mainMixerNode
        mainMixer.outputVolume = 1.5 // Amplification modérée même en mode simple
        self.mainMixer = mainMixer
        
        let recordingMixer = AVAudioMixerNode()
        recordingMixer.outputVolume = 1.0
        self.recordingMixer = recordingMixer
        engine.attach(recordingMixer)
        
        let inputFormat = inputNode.inputFormat(forBus: 0)
        guard inputFormat.sampleRate > 0 && inputFormat.channelCount > 0 else {
            print("❌ Cannot proceed with invalid format in simplified setup")
            return
        }
        
        self.connectionFormat = inputFormat
        
        do {
            try engine.connect(inputNode, to: recordingMixer, format: inputFormat)
            try engine.connect(recordingMixer, to: mainMixer, format: inputFormat)
            try engine.connect(mainMixer, to: engine.outputNode, format: nil)
            
            engine.prepare()
            print("✅ Simplified QUALITY configuration successful")
            setupAttempts = 0
        } catch {
            print("❌ Simplified quality configuration failed: \(error)")
        }
    }
    
    // MARK: - Advanced Parameters (reste identique)
    
    private func applyAdvancedParameters(to reverb: AVAudioUnitReverb, preset: ReverbPreset) {
        let audioUnit = reverb.audioUnit
        
        let kDecayTimeParameter: AudioUnitParameterID = 7
        let kHFDampingParameter: AudioUnitParameterID = 9
        let kRoomSizeParameter: AudioUnitParameterID = 1000
        let kDensityParameter: AudioUnitParameterID = 10
        let kPreDelayParameter: AudioUnitParameterID = 5
        
        if preset == .custom {
            let decayTime = max(0.1, min(8.0, preset.decayTime))
            safeSetParameter(audioUnit: audioUnit, paramID: kDecayTimeParameter, value: decayTime)
            
            reverb.wetDryMix = preset.wetDryMix
            
            safeSetParameter(audioUnit: audioUnit, paramID: kPreDelayParameter,
                          value: max(0, min(0.5, preset.preDelay / 1000.0)))
            
            safeSetParameter(audioUnit: audioUnit, paramID: kRoomSizeParameter,
                          value: max(0, min(1, preset.roomSize / 100.0)))
            
            safeSetParameter(audioUnit: audioUnit, paramID: kDensityParameter,
                          value: max(0, min(1, preset.density / 100.0)))
            
            safeSetParameter(audioUnit: audioUnit, paramID: kHFDampingParameter,
                          value: max(0, min(1, preset.highFrequencyDamping / 100.0)))
            
        } else {
            let decayTime = max(0.1, min(5.0, preset.decayTime))
            safeSetParameter(audioUnit: audioUnit, paramID: kDecayTimeParameter, value: decayTime)
            
            safeSetParameter(audioUnit: audioUnit, paramID: kHFDampingParameter,
                           value: max(0, min(1, preset.highFrequencyDamping / 100.0)))
        }
    }
    
    private func safeSetParameter(audioUnit: AudioUnit?, paramID: AudioUnitParameterID, value: Float) {
        guard let audioUnit = audioUnit else { return }
        
        let clampedValue = max(-100, min(100, value))
        
        let status = AudioUnitSetParameter(
            audioUnit,
            paramID,
            kAudioUnitScope_Global,
            0,
            clampedValue,
            0
        )
        
        if status != noErr {
            print("⚠️ Parameter ID \(paramID) not available (error \(status))")
        }
    }
    
    func updateCrossFeed(enabled: Bool, value: Float) {
        crossFeedEnabled = enabled
    }
    
    func diagnosticMonitoring() {
        print("🔍 === DIAGNOSTIC QUALITÉ OPTIMISÉE ===")
        
        guard let engine = audioEngine else {
            print("❌ No audio engine")
            return
        }
        
        print("🎵 Quality-Optimized Engine Status:")
        print("   - Engine running: \(engine.isRunning)")
        print("   - Current preset: \(currentPreset.rawValue)")
        print("   - Reverb bypass: \(reverbNode?.bypass ?? true)")
        print("   - Reverb wetDryMix: \(reverbNode?.wetDryMix ?? 0)")
        print("   - Input volume: \(inputNode?.volume ?? 0) (\(Int((inputNode?.volume ?? 0) * 100))%)")
        print("   - Gain mixer: \(gainMixer?.volume ?? 0) (\(Int((gainMixer?.volume ?? 0) * 100))%)")
        print("   - Clean bypass: \(cleanBypassMixer?.volume ?? 0) (\(Int((cleanBypassMixer?.volume ?? 0) * 100))%)")
        print("   - Main mixer: \(mainMixer?.outputVolume ?? 0) (\(Int((mainMixer?.outputVolume ?? 0) * 100))%)")
        print("   - Recording mixer: \(recordingMixer?.outputVolume ?? 0) (\(Int((recordingMixer?.outputVolume ?? 0) * 100))%)")
        print("   - OPTIMAL TOTAL GAIN: x\(getOptimalGainFactor())")
        print("   - Connection format: \(connectionFormat?.description ?? "none")")
        
        #if os(macOS)
        let micAccess = AVCaptureDevice.authorizationStatus(for: .audio)
        print("   - Microphone access: \(micAccess == .authorized ? "✅" : "❌")")
        #endif
        
        print("=== FIN DIAGNOSTIC QUALITÉ ===")
    }
    
    deinit {
        cleanupEngine()
        
        #if os(iOS)
        do {
            try AVAudioSession.sharedInstance().setActive(false)
        } catch {
            print("Error deactivating audio session: \(error)")
        }
        #endif
    }
}

=== Reverb/RecordingHistory.swift ===
import Foundation

struct RecordingSession: Identifiable, Codable {
    var id = UUID()
    var date: Date
    var duration: TimeInterval
    var presetUsed: String
    
    static var mockSessions: [RecordingSession] {
        [
            RecordingSession(date: Date().addingTimeInterval(-3600), duration: 120, presetUsed: "Cathédrale"),
            RecordingSession(date: Date().addingTimeInterval(-7200), duration: 180, presetUsed: "Grande Salle")
        ]
    }
}

class RecordingHistory: ObservableObject {
    @Published var sessions: [RecordingSession] = []
    private let sessionsKey = "recordingSessions"
    
    init() {
        loadSessions()
    }
    
    func addSession(preset: String, duration: TimeInterval) {
        let newSession = RecordingSession(date: Date(), duration: duration, presetUsed: preset)
        sessions.append(newSession)
        saveSessions()
    }
    
    private func saveSessions() {
        if let encoded = try? JSONEncoder().encode(sessions) {
            UserDefaults.standard.set(encoded, forKey: sessionsKey)
        }
    }
    
    private func loadSessions() {
        if let data = UserDefaults.standard.data(forKey: sessionsKey),
           let decoded = try? JSONDecoder().decode([RecordingSession].self, from: data) {
            sessions = decoded
        }
    }
    
    func clearHistory() {
        sessions.removeAll()
        saveSessions()
    }
} 

=== Reverb/ReverbApp.swift ===
import SwiftUI

@main
struct ReverbApp: App {
    var body: some Scene {
        WindowGroup {
            ContentView()
        }
        #if os(macOS)
        .windowStyle(HiddenTitleBarWindowStyle())
        .windowResizability(.contentSize)
        #endif
    }
} 


=== Reverb/ContentView.swift ===
import SwiftUI
import AVFoundation
#if os(iOS)
import UIKit
#elseif os(macOS)
import AppKit
#endif

struct ContentView: View {
    @StateObject private var audioManager = AudioManager.shared
    @StateObject private var recordingHistory = RecordingHistory()
    
    // États locaux
    @State private var isMonitoring = false
    @State private var masterVolume: Float = 1.5
    @State private var micGain: Float = 1.2
    @State private var isMuted = false
    @State private var selectedReverbPreset: ReverbPreset = .vocalBooth
    @State private var recordings: [URL] = []
    @State private var recordingToDelete: URL?
    @State private var showDeleteAlert = false
    
    // States spécifiques macOS
    @State private var windowWidth: CGFloat = 800
    
    // Player local
    @StateObject private var audioPlayer = LocalAudioPlayer()
    
    // Couleurs du thème
    private let backgroundColor = Color(red: 0.08, green: 0.08, blue: 0.13)
    private let cardColor = Color(red: 0.12, green: 0.12, blue: 0.18)
    private let accentColor = Color.blue
    
    var body: some View {
        ZStack {
            backgroundColor.ignoresSafeArea()
            
            GeometryReader { geometry in
                ScrollView(.vertical, showsIndicators: true) {
                    VStack(spacing: adaptiveSpacing) {
                        headerSection
                        
                        if isCompactLayout {
                            compactLayout
                        } else {
                            expandedLayout
                        }
                        
                        Color.clear.frame(height: 20)
                    }
                    .padding(.horizontal, adaptivePadding)
                    .padding(.top, 5)
                }
                .onAppear {
                    windowWidth = geometry.size.width
                }
                .onChange(of: geometry.size.width) { newWidth in
                    windowWidth = newWidth
                }
            }
        }
        .onAppear {
            setupAudio()
            loadRecordings()
        }
        .alert("Supprimer l'enregistrement", isPresented: $showDeleteAlert) {
            Button("Supprimer", role: .destructive) {
                deleteSelectedRecording()
            }
            Button("Annuler", role: .cancel) { }
        }
        #if os(macOS)
        .frame(minWidth: 600, minHeight: 500)
        .background(WindowAccessor { window in
            window?.title = "Reverb Studio - Enregistrement Audio"
            window?.titlebarAppearsTransparent = true
            window?.titleVisibility = .hidden
        })
        #endif
    }
    
    // MARK: - Layout Properties
    
    private var isCompactLayout: Bool {
        #if os(iOS)
        return true
        #else
        return windowWidth < 800
        #endif
    }
    
    private var adaptiveSpacing: CGFloat {
        #if os(macOS)
        return isCompactLayout ? 12 : 16
        #else
        return 16
        #endif
    }
    
    private var adaptivePadding: CGFloat {
        #if os(macOS)
        return isCompactLayout ? 16 : 24
        #else
        return 16
        #endif
    }
    
    // MARK: - LAYOUTS
    
    @ViewBuilder
    private var compactLayout: some View {
        audioLevelSection
        volumeControlsSection
        monitoringSection
        reverbPresetsSection
        
        if isMonitoring {
            recordingSection
        }
        
        recordingsListSection
    }
    
    @ViewBuilder
    private var expandedLayout: some View {
        audioLevelSection
        
        HStack(alignment: .top, spacing: 20) {
            VStack(spacing: 16) {
                volumeControlsSection
                monitoringSection
                
                if isMonitoring {
                    recordingSection
                }
            }
            .frame(maxWidth: 350)
            
            VStack(spacing: 16) {
                reverbPresetsSection
                recordingsListSection
            }
            .frame(maxWidth: 400)
        }
    }
    
    // MARK: - HEADER SECTION
    
    private var headerSection: some View {
        VStack(spacing: 4) {
            HStack {
                Text("🎙️ Reverb Studio")
                    .font(.system(size: adaptiveTitleSize, weight: .bold, design: .rounded))
                    .foregroundColor(.white)
                
                Spacer()
                
                #if os(macOS)
                HStack(spacing: 4) {
                    Image(systemName: "laptopcomputer")
                        .font(.caption)
                        .foregroundColor(.white.opacity(0.6))
                    Text("macOS")
                        .font(.caption2)
                        .foregroundColor(.white.opacity(0.6))
                }
                #endif
            }
            
            Text("Enregistrement avec réverbération optimisée")
                .font(.caption)
                .foregroundColor(.white.opacity(0.6))
        }
        .padding(.vertical, 8)
    }
    
    private var adaptiveTitleSize: CGFloat {
        #if os(macOS)
        return isCompactLayout ? 20 : 26
        #else
        return 24
        #endif
    }
    
    // MARK: - NIVEAU AUDIO
    
    private var audioLevelSection: some View {
        VStack(spacing: 6) {
            Text("Niveau Audio")
                .font(.caption)
                .fontWeight(.medium)
                .foregroundColor(.white)
            
            GeometryReader { geometry in
                ZStack(alignment: .leading) {
                    RoundedRectangle(cornerRadius: 4)
                        .fill(Color.gray.opacity(0.3))
                        .frame(height: 10)
                    
                    RoundedRectangle(cornerRadius: 4)
                        .fill(LinearGradient(
                            gradient: Gradient(colors: [.green, .yellow, .red]),
                            startPoint: .leading,
                            endPoint: .trailing
                        ))
                        .frame(width: geometry.size.width * CGFloat(audioManager.currentAudioLevel), height: 10)
                        .animation(.easeInOut(duration: 0.1), value: audioManager.currentAudioLevel)
                }
            }
            .frame(height: 10)
            
            Text("\(Int(audioManager.currentAudioLevel * 100))%")
                .font(.caption2)
                .foregroundColor(.white.opacity(0.8))
                .monospacedDigit()
        }
        .padding(12)
        .background(cardColor)
        .cornerRadius(10)
    }
    
    // MARK: - CONTRÔLES VOLUME
    
    private var volumeControlsSection: some View {
        VStack(spacing: 12) {
            HStack {
                Text("🎵 Contrôles Audio Optimisés")
                    .font(.subheadline)
                    .fontWeight(.semibold)
                    .foregroundColor(.white)
                
                #if os(macOS)
                Spacer()
                Text("Double-clic pour réinitialiser")
                    .font(.caption2)
                    .foregroundColor(.white.opacity(0.5))
                #endif
            }
            
            // GAIN MICROPHONE
            VStack(spacing: 6) {
                HStack {
                    Image(systemName: "mic.fill")
                        .foregroundColor(.green)
                    Text("Gain Microphone")
                        .font(.caption)
                        .fontWeight(.medium)
                        .foregroundColor(.white)
                    Spacer()
                    Text("\(Int(micGain * 100))%" + getGainLabel(micGain))
                        .foregroundColor(getGainColor(micGain))
                        .font(.caption)
                        .monospacedDigit()
                }
                
                HStack {
                    Slider(value: $micGain, in: 0.2...3.0, step: 0.1)
                        .accentColor(.green)
                        .onChange(of: micGain) { newValue in
                            audioManager.setInputVolume(newValue)
                            print("🎵 Quality Gain micro: \(Int(newValue * 100))%")
                        }
                        #if os(macOS)
                        .onTapGesture(count: 2) {
                            micGain = 1.2
                        }
                        #endif
                }
                
                HStack {
                    Text("20%")
                        .font(.caption2)
                        .foregroundColor(.gray)
                    Spacer()
                    Text("DOUX")
                        .font(.caption2)
                        .foregroundColor(.green)
                    Spacer()
                    Text("OPTIMAL")
                        .font(.caption2)
                        .foregroundColor(.blue)
                    Spacer()
                    Text("FORT")
                        .font(.caption2)
                        .foregroundColor(.orange)
                    Spacer()
                    Text("300%")
                        .font(.caption2)
                        .foregroundColor(.orange)
                }
                
                qualityIndicator(for: micGain, type: .microphone)
            }
            .padding(10)
            .background(cardColor.opacity(0.7))
            .cornerRadius(8)
            
            // VOLUME MONITORING
            VStack(spacing: 6) {
                HStack {
                    Image(systemName: isMuted ? "speaker.slash" : "speaker.wave.3")
                        .foregroundColor(isMuted ? .red : accentColor)
                    Text("Volume Monitoring")
                        .font(.caption)
                        .fontWeight(.medium)
                        .foregroundColor(.white)
                    Spacer()
                    
                    Button(action: {
                        isMuted.toggle()
                        audioManager.setOutputVolume(masterVolume, isMuted: isMuted)
                    }) {
                        Image(systemName: isMuted ? "speaker.slash.fill" : "speaker.wave.3.fill")
                            .foregroundColor(isMuted ? .red : accentColor)
                            .font(.body)
                    }
                    #if os(macOS)
                    .buttonStyle(PlainButtonStyle())
                    .onHover { hovering in
                        if hovering { NSCursor.pointingHand.set() }
                    }
                    #endif
                }
                
                if !isMuted {
                    Slider(value: $masterVolume, in: 0...2.5, step: 0.05)
                        .accentColor(accentColor)
                        .onChange(of: masterVolume) { newValue in
                            audioManager.setOutputVolume(newValue, isMuted: isMuted)
                            print("🔊 Quality Volume: \(Int(newValue * 100))%")
                        }
                        #if os(macOS)
                        .onTapGesture(count: 2) {
                            masterVolume = 1.5
                        }
                        #endif
                    
                    HStack {
                        Text("Silence")
                            .font(.caption2)
                            .foregroundColor(.gray)
                        Spacer()
                        Text("DOUX")
                            .font(.caption2)
                            .foregroundColor(.green)
                        Spacer()
                        Text("OPTIMAL")
                            .font(.caption2)
                            .foregroundColor(.blue)
                        Spacer()
                        Text("FORT")
                            .font(.caption2)
                            .foregroundColor(.orange)
                        Spacer()
                        Text("250%")
                            .font(.caption2)
                            .foregroundColor(.orange)
                    }
                    
                    Text("\(Int(masterVolume * 100))%" + getVolumeQualityLabel(masterVolume))
                        .foregroundColor(getVolumeQualityColor(masterVolume))
                        .font(.caption)
                        .fontWeight(.semibold)
                        .monospacedDigit()
                    
                    qualityIndicator(for: masterVolume, type: .volume)
                } else {
                    Text("🔇 SILENCIEUX")
                        .foregroundColor(.red)
                        .font(.caption)
                        .padding(4)
                }
            }
            .padding(10)
            .background(cardColor)
            .cornerRadius(8)
            .opacity(isMuted ? 0.7 : 1.0)
            
            // Indicateur de qualité totale
            if isMonitoring {
                HStack {
                    Text("🎵 GAIN TOTAL OPTIMAL:")
                        .font(.caption2)
                        .foregroundColor(.white.opacity(0.8))
                    
                    Spacer()
                    
                    let totalGain = micGain * masterVolume * 1.3
                    Text("x\(String(format: "%.1f", totalGain))")
                        .font(.caption2)
                        .foregroundColor(totalGain > 4.0 ? .orange : .green)
                        .fontWeight(.bold)
                        .monospacedDigit()
                    
                    Text(totalGain > 4.0 ? "(Élevé)" : "(Optimal)")
                        .font(.caption2)
                        .foregroundColor(totalGain > 4.0 ? .orange : .green)
                }
                .padding(8)
                .background((micGain * masterVolume * 1.3) > 4.0 ? Color.orange.opacity(0.1) : Color.green.opacity(0.1))
                .cornerRadius(6)
            }
        }
    }
    
    // MARK: - MONITORING SECTION
    
    private var monitoringSection: some View {
        VStack(spacing: 8) {
            Button(action: {
                toggleMonitoring()
            }) {
                HStack(spacing: 8) {
                    Image(systemName: isMonitoring ? "stop.circle.fill" : "play.circle.fill")
                        .font(.title2)
                    Text(isMonitoring ? "🔴 Arrêter Monitoring" : "▶️ Démarrer Monitoring")
                        .font(.subheadline)
                        .fontWeight(.semibold)
                }
                .foregroundColor(.white)
                .padding(.vertical, 12)
                .frame(maxWidth: .infinity)
                .background(isMonitoring ? Color.red : accentColor)
                .cornerRadius(10)
            }
            #if os(macOS)
            .buttonStyle(PlainButtonStyle())
            .onHover { hovering in
                if hovering { NSCursor.pointingHand.set() }
            }
            .keyboardShortcut(isMonitoring ? "s" : "p", modifiers: .command)
            #endif
            
            if isMonitoring {
                HStack(spacing: 4) {
                    Circle()
                        .fill(Color.green)
                        .frame(width: 6, height: 6)
                        .scaleEffect(1.0)
                        .animation(.easeInOut(duration: 1).repeatForever(autoreverses: true), value: isMonitoring)
                    
                    Text("Monitoring actif • Volumes ajustables en temps réel")
                        .font(.caption2)
                        .foregroundColor(.green)
                        .fontWeight(.medium)
                    
                    #if os(macOS)
                    Spacer()
                    Text("⌘P/⌘S pour contrôler")
                        .font(.caption2)
                        .foregroundColor(.white.opacity(0.5))
                    #endif
                }
                .padding(.horizontal, 4)
            }
        }
    }
    
    // MARK: - PRESETS REVERB
    
    private var reverbPresetsSection: some View {
        VStack(alignment: .leading, spacing: 10) {
            Text("🎛️ Modes de Réverbération")
                .font(.subheadline)
                .fontWeight(.semibold)
                .foregroundColor(.white)
            
            let columns = Array(repeating: GridItem(.flexible(), spacing: 8), count: adaptiveColumnCount)
            LazyVGrid(columns: columns, spacing: 8) {
                ForEach(ReverbPreset.allCases, id: \.id) { preset in
                    Button(action: {
                        if isMonitoring {
                            selectedReverbPreset = preset
                            audioManager.updateReverbPreset(preset)
                        }
                    }) {
                        VStack(spacing: 4) {
                            Text(getPresetEmoji(preset))
                                .font(adaptivePresetEmojiSize)
                            
                            Text(getPresetName(preset))
                                .font(.caption)
                                .fontWeight(.medium)
                                .multilineTextAlignment(.center)
                        }
                        .foregroundColor(selectedReverbPreset == preset ? .white : .white.opacity(0.7))
                        .frame(maxWidth: .infinity, minHeight: adaptivePresetHeight)
                        .background(
                            selectedReverbPreset == preset ?
                            accentColor : cardColor.opacity(0.8)
                        )
                        .cornerRadius(8)
                        .overlay(
                            RoundedRectangle(cornerRadius: 8)
                                .stroke(selectedReverbPreset == preset ? .white.opacity(0.3) : .clear, lineWidth: 1)
                        )
                        .scaleEffect(selectedReverbPreset == preset ? 1.05 : 1.0)
                        .animation(.easeInOut(duration: 0.15), value: selectedReverbPreset == preset)
                    }
                    .disabled(!isMonitoring)
                    .opacity(isMonitoring ? 1.0 : 0.5)
                    #if os(macOS)
                    .buttonStyle(PlainButtonStyle())
                    .onHover { hovering in
                        if isMonitoring && hovering { NSCursor.pointingHand.set() }
                    }
                    #endif
                }
            }
            
            if isMonitoring {
                Text("Effet: \(selectedReverbPreset.rawValue) - \(getPresetDescription(selectedReverbPreset))")
                    .font(.caption2)
                    .foregroundColor(.white.opacity(0.8))
                    .padding(8)
                    .background(cardColor.opacity(0.5))
                    .cornerRadius(6)
            }
        }
    }
    
    private var adaptiveColumnCount: Int {
        #if os(macOS)
        return isCompactLayout ? 3 : 5
        #else
        return 3
        #endif
    }
    
    private var adaptivePresetEmojiSize: Font {
        #if os(macOS)
        return isCompactLayout ? .title3 : .title2
        #else
        return .title2
        #endif
    }
    
    private var adaptivePresetHeight: CGFloat {
        #if os(macOS)
        return isCompactLayout ? 50 : 65
        #else
        return 60
        #endif
    }
    
    // MARK: - SECTION ENREGISTREMENT
    
    private var recordingSection: some View {
        VStack(spacing: 10) {
            Text("🎙️ Enregistrement")
                .font(.subheadline)
                .fontWeight(.semibold)
                .foregroundColor(.white)
            
            HStack(spacing: 12) {
                Button(action: {
                    handleRecordingToggle()
                }) {
                    HStack(spacing: 6) {
                        Image(systemName: audioManager.isRecording ? "stop.circle.fill" : "record.circle")
                            .font(.title3)
                        Text(audioManager.isRecording ? "🔴 Arrêter" : "⏺️ Enregistrer")
                            .font(.subheadline)
                            .fontWeight(.medium)
                    }
                    .foregroundColor(.white)
                    .padding(.vertical, 10)
                    .frame(maxWidth: .infinity)
                    .background(audioManager.isRecording ? Color.red : Color.orange)
                    .cornerRadius(8)
                }
                #if os(macOS)
                .buttonStyle(PlainButtonStyle())
                .keyboardShortcut("r", modifiers: .command)
                #endif
                
                Button(action: {
                    loadRecordings()
                }) {
                    VStack(spacing: 2) {
                        Image(systemName: "list.bullet")
                            .font(.body)
                        Text("\(recordings.count)")
                            .font(.caption2)
                    }
                    .foregroundColor(.white)
                    .padding(8)
                    .background(Color.gray.opacity(0.6))
                    .cornerRadius(8)
                }
                #if os(macOS)
                .buttonStyle(PlainButtonStyle())
                #endif
            }
            
            if audioManager.isRecording {
                HStack(spacing: 4) {
                    Circle()
                        .fill(Color.red)
                        .frame(width: 6, height: 6)
                        .scaleEffect(1.0)
                        .animation(.easeInOut(duration: 1).repeatForever(autoreverses: true), value: audioManager.isRecording)
                    
                    Text("🔴 Enregistrement avec \(selectedReverbPreset.rawValue)...")
                        .font(.caption)
                        .foregroundColor(.red)
                        .fontWeight(.medium)
                    
                    #if os(macOS)
                    Spacer()
                    Text("⌘R pour arrêter")
                        .font(.caption2)
                        .foregroundColor(.white.opacity(0.5))
                    #endif
                }
            } else if let filename = audioManager.lastRecordingFilename {
                Text("✅ Dernier: \(filename)")
                    .font(.caption2)
                    .foregroundColor(.green)
                    .lineLimit(1)
                    .truncationMode(.middle)
            }
        }
        .padding(12)
        .background(cardColor.opacity(0.8))
        .cornerRadius(10)
    }
    
    // MARK: - LISTE ENREGISTREMENTS
    
    private var recordingsListSection: some View {
        VStack(alignment: .leading, spacing: 10) {
            HStack {
                Text("📂 Enregistrements (\(recordings.count))")
                    .font(.subheadline)
                    .fontWeight(.semibold)
                    .foregroundColor(.white)
                
                Spacer()
                
                Button("🔄") {
                    loadRecordings()
                }
                .foregroundColor(accentColor)
                #if os(macOS)
                .buttonStyle(PlainButtonStyle())
                #endif
            }
            
            if recordings.isEmpty {
                VStack(spacing: 8) {
                    Image(systemName: "waveform.circle")
                        .font(.system(size: 30))
                        .foregroundColor(.white.opacity(0.3))
                    Text("Aucun enregistrement")
                        .font(.caption)
                        .foregroundColor(.white.opacity(0.6))
                    
                    #if os(macOS)
                    Text("Les fichiers sont sauvés dans ~/Documents/Recordings")
                        .font(.caption2)
                        .foregroundColor(.white.opacity(0.4))
                        .multilineTextAlignment(.center)
                    #endif
                }
                .frame(maxWidth: .infinity)
                .padding(20)
                .background(cardColor.opacity(0.5))
                .cornerRadius(8)
            } else {
                LazyVStack(spacing: 6) {
                    ForEach(recordings.prefix(adaptiveRecordingCount), id: \.self) { recording in
                        recordingRowView(recording: recording)
                    }
                    
                    if recordings.count > adaptiveRecordingCount {
                        Text("... et \(recordings.count - adaptiveRecordingCount) autre(s)")
                            .font(.caption2)
                            .foregroundColor(.white.opacity(0.6))
                            .frame(maxWidth: .infinity, alignment: .center)
                            .padding(8)
                    }
                }
            }
        }
        .padding(12)
        .background(cardColor.opacity(0.3))
        .cornerRadius(10)
    }
    
    private var adaptiveRecordingCount: Int {
        #if os(macOS)
        return isCompactLayout ? 4 : 8
        #else
        return 5
        #endif
    }
    
    // MARK: - ROW ENREGISTREMENT
    
    @ViewBuilder
    private func recordingRowView(recording: URL) -> some View {
        HStack(spacing: 10) {
            Button(action: {
                togglePlayback(recording: recording)
            }) {
                Image(systemName: getPlayButtonIcon(recording: recording))
                    .font(.title3)
                    .foregroundColor(isCurrentlyPlaying(recording) ? .red : accentColor)
                    .frame(width: 32, height: 32)
                    .background(Circle().fill(cardColor))
            }
            #if os(macOS)
            .buttonStyle(PlainButtonStyle())
            .onHover { hovering in
                if hovering { NSCursor.pointingHand.set() }
            }
            #endif
            
            VStack(alignment: .leading, spacing: 2) {
                Text(getDisplayName(recording))
                    .font(.caption)
                    .fontWeight(.medium)
                    .foregroundColor(.white)
                    .lineLimit(1)
                
                HStack(spacing: 6) {
                    Text(getRecordingDuration(recording))
                        .font(.caption2)
                        .foregroundColor(.white.opacity(0.7))
                    
                    Text("•")
                        .font(.caption2)
                        .foregroundColor(.white.opacity(0.5))
                    
                    Text(getFileSize(recording))
                        .font(.caption2)
                        .foregroundColor(.white.opacity(0.7))
                    
                    Text("•")
                        .font(.caption2)
                        .foregroundColor(.white.opacity(0.5))
                    
                    Text(recording.pathExtension.uppercased())
                        .font(.caption2)
                        .foregroundColor(.white.opacity(0.5))
                    
                    #if os(macOS)
                    Text("•")
                        .font(.caption2)
                        .foregroundColor(.white.opacity(0.5))
                    
                    Text(getCreationDate(recording))
                        .font(.caption2)
                        .foregroundColor(.white.opacity(0.5))
                    #endif
                }
            }
            
            Spacer()
            
            HStack(spacing: 8) {
                #if os(macOS)
                Button(action: {
                    revealInFinder(recording)
                }) {
                    Image(systemName: "folder")
                        .font(.caption)
                        .foregroundColor(.blue)
                }
                .buttonStyle(PlainButtonStyle())
                .help("Afficher dans le Finder")
                #endif
                
                Button(action: {
                    shareRecording(recording)
                }) {
                    Image(systemName: "square.and.arrow.up")
                        .font(.caption)
                        .foregroundColor(accentColor)
                }
                #if os(macOS)
                .buttonStyle(PlainButtonStyle())
                .help("Partager")
                #endif
                
                Button(action: {
                    recordingToDelete = recording
                    showDeleteAlert = true
                }) {
                    Image(systemName: "trash")
                        .font(.caption)
                        .foregroundColor(.red.opacity(0.8))
                }
                #if os(macOS)
                .buttonStyle(PlainButtonStyle())
                .help("Supprimer")
                #endif
            }
        }
        .padding(8)
        .background(cardColor.opacity(0.6))
        .cornerRadius(6)
        #if os(macOS)
        .contextMenu {
            Button("Lire/Pause") {
                togglePlayback(recording: recording)
            }
            
            Button("Afficher dans le Finder") {
                revealInFinder(recording)
            }
            
            Button("Partager") {
                shareRecording(recording)
            }
            
            Divider()
            
            Button("Supprimer", role: .destructive) {
                recordingToDelete = recording
                showDeleteAlert = true
            }
        }
        #endif
    }
    
    // MARK: - HELPER FUNCTIONS
    
    private func setupAudio() {
        audioManager.prepareAudio()
        audioManager.setInputVolume(micGain)
        audioManager.setOutputVolume(masterVolume, isMuted: isMuted)
    }
    
    private func toggleMonitoring() {
        isMonitoring.toggle()
        if isMonitoring {
            audioManager.startMonitoring()
            audioManager.updateReverbPreset(selectedReverbPreset)
            audioManager.setInputVolume(micGain)
            audioManager.setOutputVolume(masterVolume, isMuted: isMuted)
        } else {
            audioManager.stopMonitoring()
        }
    }
    
    private func handleRecordingToggle() {
        if audioManager.isRecording {
            audioManager.stopRecording { success, filename, duration in
                if success {
                    recordingHistory.addSession(preset: selectedReverbPreset.rawValue, duration: duration)
                    loadRecordings()
                }
            }
        } else {
            audioManager.startRecording { success in
                if !success {
                    print("❌ Échec de l'enregistrement")
                }
            }
        }
    }
    
    private func loadRecordings() {
        let documentsPath: URL
        
        #if os(macOS)
        documentsPath = FileManager.default.homeDirectoryForCurrentUser.appendingPathComponent("Documents")
        #else
        documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
        #endif
        
        let recordingsPath = documentsPath.appendingPathComponent("Recordings")
        
        if !FileManager.default.fileExists(atPath: recordingsPath.path) {
            do {
                try FileManager.default.createDirectory(at: recordingsPath, withIntermediateDirectories: true)
                print("✅ Created Recordings directory at: \(recordingsPath.path)")
            } catch {
                print("❌ Failed to create directory: \(error)")
                return
            }
        }
        
        do {
            let files = try FileManager.default.contentsOfDirectory(
                at: recordingsPath,
                includingPropertiesForKeys: [.creationDateKey]
            )
            
            recordings = files.filter { url in
                ["wav", "mp3", "aac", "m4a"].contains(url.pathExtension.lowercased())
            }.sorted { url1, url2 in
                let date1 = (try? url1.resourceValues(forKeys: [.creationDateKey]))?.creationDate ?? Date.distantPast
                let date2 = (try? url2.resourceValues(forKeys: [.creationDateKey]))?.creationDate ?? Date.distantPast
                return date1 > date2
            }
            
            print("📂 Loaded \(recordings.count) recordings from: \(recordingsPath.path)")
        } catch {
            recordings = []
            print("❌ Error loading recordings: \(error)")
        }
    }
    
    private func togglePlayback(recording: URL) {
        if isCurrentlyPlaying(recording) {
            audioPlayer.pausePlayback()
        } else {
            audioPlayer.playRecording(at: recording)
        }
    }
    
    private func isCurrentlyPlaying(_ recording: URL) -> Bool {
        return audioPlayer.isPlaying && audioPlayer.currentRecordingURL == recording
    }
    
    private func getPlayButtonIcon(recording: URL) -> String {
        return isCurrentlyPlaying(recording) ? "pause.circle.fill" : "play.circle.fill"
    }
    
    private func shareRecording(_ recording: URL) {
        #if os(iOS)
        let activityController = UIActivityViewController(activityItems: [recording], applicationActivities: nil)
        
        if let windowScene = UIApplication.shared.connectedScenes.first as? UIWindowScene,
           let window = windowScene.windows.first,
           let rootViewController = window.rootViewController {
            rootViewController.present(activityController, animated: true)
        }
        #elseif os(macOS)
        let sharingService = NSSharingServicePicker(items: [recording])
        
        if let window = NSApplication.shared.mainWindow,
           let contentView = window.contentView {
            let rect = NSRect(x: contentView.bounds.midX - 10, y: contentView.bounds.midY - 10, width: 20, height: 20)
            sharingService.show(relativeTo: rect, of: contentView, preferredEdge: .minY)
        }
        #endif
    }
    
    #if os(macOS)
    private func revealInFinder(_ recording: URL) {
        NSWorkspace.shared.selectFile(recording.path, inFileViewerRootedAtPath: "")
    }
    #endif
    
    private func deleteSelectedRecording() {
        guard let recording = recordingToDelete else { return }
        
        do {
            try FileManager.default.removeItem(at: recording)
            loadRecordings()
            print("✅ Recording deleted: \(recording.lastPathComponent)")
        } catch {
            print("❌ Erreur suppression: \(error)")
        }
        
        recordingToDelete = nil
    }
    
    // MARK: - Helper Functions pour styling
    
    @ViewBuilder
    private func qualityIndicator(for value: Float, type: QualityType) -> some View {
        let (message, color, background) = getQualityInfo(value: value, type: type)
        
        if !message.isEmpty {
            Text(message)
                .font(.caption2)
                .foregroundColor(color)
                .padding(4)
                .background(background)
                .cornerRadius(4)
        }
    }
    
    private enum QualityType {
        case microphone, volume
    }
    
    private func getQualityInfo(value: Float, type: QualityType) -> (String, Color, Color) {
        switch type {
        case .microphone:
            if value > 2.5 {
                return ("⚠️ GAIN ÉLEVÉ - Vérifier la qualité", .orange, Color.orange.opacity(0.2))
            } else if value > 1.5 {
                return ("✅ GAIN OPTIMAL - Bonne qualité", .blue, Color.clear)
            } else {
                return ("🎵 GAIN DOUX - Qualité maximale", .green, Color.clear)
            }
        case .volume:
            if value > 2.0 {
                return ("⚠️ VOLUME ÉLEVÉ - Surveiller la qualité", .orange, Color.orange.opacity(0.2))
            } else if value > 1.2 {
                return ("✅ VOLUME OPTIMAL - Parfait équilibre", .blue, Color.clear)
            } else {
                return ("🎵 VOLUME DOUX - Qualité premium", .green, Color.clear)
            }
        }
    }
    
    private func getGainLabel(_ gain: Float) -> String {
        if gain > 2.5 { return " (Élevé)" }
        else if gain > 1.5 { return " (Optimal)" }
        else { return " (Doux)" }
    }
    
    private func getGainColor(_ gain: Float) -> Color {
        if gain > 2.5 { return .orange }
        else if gain > 1.5 { return .blue }
        else { return .green }
    }
    
    private func getVolumeQualityLabel(_ volume: Float) -> String {
        if volume > 2.0 { return " (Fort)" }
        else if volume > 1.2 { return " (Optimal)" }
        else { return " (Doux)" }
    }
    
    private func getVolumeQualityColor(_ volume: Float) -> Color {
        if volume > 2.0 { return .orange }
        else if volume > 1.2 { return .blue }
        else { return .green }
    }
    
    private func getPresetEmoji(_ preset: ReverbPreset) -> String {
        switch preset {
        case .clean: return "🎤"
        case .vocalBooth: return "🎙️"
        case .studio: return "🎧"
        case .cathedral: return "⛪"
        case .custom: return "🎛️"
        }
    }
    
    private func getPresetName(_ preset: ReverbPreset) -> String {
        switch preset {
        case .clean: return "Clean"
        case .vocalBooth: return "Vocal\nBooth"
        case .studio: return "Studio"
        case .cathedral: return "Cathedral"
        case .custom: return "Custom"
        }
    }
    
    private func getPresetDescription(_ preset: ReverbPreset) -> String {
        switch preset {
        case .clean: return "Aucun effet"
        case .vocalBooth: return "Ambiance feutrée"
        case .studio: return "Équilibre professionnel"
        case .cathedral: return "Écho spacieux"
        case .custom: return "Paramètres personnalisés"
        }
    }
    
    private func getDisplayName(_ recording: URL) -> String {
        let name = recording.deletingPathExtension().lastPathComponent
        return name.replacingOccurrences(of: "_", with: " ")
            .replacingOccurrences(of: "safe reverb", with: "Reverb")
            .capitalized
    }
    
    private func getRecordingDuration(_ recording: URL) -> String {
        let asset = AVURLAsset(url: recording)
        let duration = CMTimeGetSeconds(asset.duration)
        
        if duration > 0 {
            let minutes = Int(duration) / 60
            let seconds = Int(duration) % 60
            return String(format: "%d:%02d", minutes, seconds)
        }
        return "0:00"
    }
    
    private func getFileSize(_ recording: URL) -> String {
        do {
            let attributes = try FileManager.default.attributesOfItem(atPath: recording.path)
            let bytes = attributes[.size] as? Int64 ?? 0
            
            if bytes < 1024 * 1024 {
                return "\(bytes / 1024) KB"
            } else {
                return String(format: "%.1f MB", Double(bytes) / (1024 * 1024))
            }
        } catch {
            return "? KB"
        }
    }
    
    #if os(macOS)
    private func getCreationDate(_ recording: URL) -> String {
        do {
            let attributes = try FileManager.default.attributesOfItem(atPath: recording.path)
            if let date = attributes[.creationDate] as? Date {
                let formatter = DateFormatter()
                formatter.dateStyle = .short
                formatter.timeStyle = .short
                return formatter.string(from: date)
            }
        } catch {}
        return ""
    }
    #endif
}

// MARK: - CLASSE AUDIO PLAYER LOCAL

class LocalAudioPlayer: NSObject, ObservableObject {
    @Published var isPlaying = false
    @Published var currentRecordingURL: URL?
    
    private var audioPlayer: AVAudioPlayer?
    
    func playRecording(at url: URL) {
        stopPlayback()
        
        do {
            audioPlayer = try AVAudioPlayer(contentsOf: url)
            audioPlayer?.delegate = self
            audioPlayer?.prepareToPlay()
            
            let success = audioPlayer?.play() ?? false
            if success {
                isPlaying = true
                currentRecordingURL = url
                print("▶️ Lecture: \(url.lastPathComponent)")
            }
        } catch {
            print("❌ Erreur lecture: \(error)")
        }
    }
    
    func pausePlayback() {
        audioPlayer?.pause()
        isPlaying = false
        print("⏸️ Lecture en pause")
    }
    
    func stopPlayback() {
        audioPlayer?.stop()
        audioPlayer = nil
        isPlaying = false
        currentRecordingURL = nil
    }
    
    func resumePlayback() -> Bool {
        guard let player = audioPlayer else { return false }
        let success = player.play()
        isPlaying = success
        return success
    }
}

// MARK: - EXTENSION DELEGATE

extension LocalAudioPlayer: AVAudioPlayerDelegate {
    func audioPlayerDidFinishPlaying(_ player: AVAudioPlayer, successfully flag: Bool) {
        DispatchQueue.main.async {
            self.isPlaying = false
            self.currentRecordingURL = nil
            print("✅ Lecture terminée")
        }
    }
    
    func audioPlayerDecodeErrorDidOccur(_ player: AVAudioPlayer, error: Error?) {
        DispatchQueue.main.async {
            self.isPlaying = false
            self.currentRecordingURL = nil
            print("❌ Erreur lecture: \(error?.localizedDescription ?? "unknown")")
        }
    }
}

// MARK: - WINDOW ACCESSOR POUR macOS

#if os(macOS)
struct WindowAccessor: NSViewRepresentable {
    let callback: (NSWindow?) -> Void
    
    func makeNSView(context: Context) -> NSView {
        let view = NSView()
        DispatchQueue.main.async {
            self.callback(view.window)
        }
        return view
    }
    
    func updateNSView(_ nsView: NSView, context: Context) {}
}
#endif

#Preview {
    ContentView()
}

